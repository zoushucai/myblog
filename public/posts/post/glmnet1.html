<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh" xml:lang="zh"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.147">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="zsc">
<title>快乐的一天 - glmnet包解读1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "没有结果",
    "search-matching-documents-text": "匹配的文档",
    "search-copy-link-title": "复制搜索链接",
    "search-hide-matches-text": "隐藏其它匹配结果",
    "search-more-match-text": "更多匹配结果",
    "search-more-matches-text": "更多匹配结果",
    "search-clear-button-title": "清除",
    "search-detached-cancel-button-title": "取消",
    "search-submit-button-title": "提交"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="快乐的一天 - glmnet包解读1">
<meta property="og:description" content="glmnet 包解决了一下问题（目标函数） \[
\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} w_i l(y_i,\beta_0+\beta^T x_i) + \lambda\left[(1-\alpha)||\beta||_2^2/2 + \alpha ||\beta||_1\right],
\] #### 1.1 glmnet包安装">
<meta property="og:site-name" content="快乐的一天">
</head>
<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg navbar-dark "><div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">快乐的一天</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item">
    <a class="nav-link" href="../../mac.html">mac</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../matlab.html">matlab</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../uncertain.html">uncertain</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/zoushucai/myblog"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
<div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">glmnet包解读1</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><header id="title-block-header" class="quarto-title-block default page-columns page-full"><div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title d-none d-lg-block">glmnet包解读1</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i></button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">显示所有代码</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">隐藏所有代码</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">查看源代码</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">r</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">作者</div>
      <div class="quarto-title-meta-contents">
               <p>zsc </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">发布日期</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2018年9月13日</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto"><div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">该页面内容</h2>
   
  <ul>
<li><a href="#%E4%BB%8B%E7%BB%8D" id="toc-介绍" class="nav-link active" data-scroll-target="#%E4%BB%8B%E7%BB%8D">1 介绍</a></li>
  <li><a href="#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B" id="toc-快速开始" class="nav-link" data-scroll-target="#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B">2 快速开始</a></li>
  <li>
<a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" id="toc-线性回归" class="nav-link" data-scroll-target="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">3 线性回归</a>
  <ul class="collapse">
<li><a href="#%E9%AB%98%E6%96%AF%E7%B0%87" id="toc-高斯簇" class="nav-link" data-scroll-target="#%E9%AB%98%E6%96%AF%E7%B0%87">3.1 高斯簇</a></li>
  <li><a href="#%E5%A4%9A%E5%93%8D%E5%BA%94%E9%AB%98%E6%96%AF%E7%B0%87" id="toc-多响应高斯簇" class="nav-link" data-scroll-target="#%E5%A4%9A%E5%93%8D%E5%BA%94%E9%AB%98%E6%96%AF%E7%B0%87">3.2 多响应高斯簇</a></li>
  </ul>
</li>
  <li>
<a href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92" id="toc-逻辑回归" class="nav-link" data-scroll-target="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92">4 逻辑回归</a>
  <ul class="collapse">
<li><a href="#%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92" id="toc-二项分布逻辑回归" class="nav-link" data-scroll-target="#%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92">4.1 二项分布逻辑回归</a></li>
  <li><a href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92" id="toc-多分类逻辑回归" class="nav-link" data-scroll-target="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92">4.2 多分类逻辑回归</a></li>
  </ul>
</li>
  <li>
<a href="#%E6%B3%8A%E6%9D%BE%E5%9B%9E%E5%BD%92" id="toc-泊松回归" class="nav-link" data-scroll-target="#%E6%B3%8A%E6%9D%BE%E5%9B%9E%E5%BD%92">5 泊松回归</a>
  <ul class="collapse">
<li><a href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86" id="toc-加载数据集" class="nav-link" data-scroll-target="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86">5.1 加载数据集</a></li>
  <li><a href="#%E6%8B%9F%E5%90%88%E6%A8%A1%E5%9E%8B-4" id="toc-拟合模型-4" class="nav-link" data-scroll-target="#%E6%8B%9F%E5%90%88%E6%A8%A1%E5%9E%8B-4">5.2 拟合模型</a></li>
  <li><a href="#%E6%9F%A5%E7%9C%8B%E6%8B%9F%E5%90%88%E6%95%88%E6%9E%9C-3" id="toc-查看拟合效果-3" class="nav-link" data-scroll-target="#%E6%9F%A5%E7%9C%8B%E6%8B%9F%E5%90%88%E6%95%88%E6%9E%9C-3">5.3 查看拟合效果</a></li>
  <li><a href="#%E9%A2%84%E6%B5%8B-3" id="toc-预测-3" class="nav-link" data-scroll-target="#%E9%A2%84%E6%B5%8B-3">5.4 预测</a></li>
  </ul>
</li>
  <li>
<a href="#cox%E6%A8%A1%E5%9E%8B" id="toc-cox模型" class="nav-link" data-scroll-target="#cox%E6%A8%A1%E5%9E%8B">6 Cox模型</a>
  <ul class="collapse">
<li><a href="#%E8%BD%BD%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86" id="toc-载入数据集" class="nav-link" data-scroll-target="#%E8%BD%BD%E5%85%A5%E6%95%B0%E6%8D%AE%E9%9B%86">6.1 载入数据集</a></li>
  <li><a href="#%E6%8B%9F%E5%90%88%E6%A8%A1%E5%9E%8B-5" id="toc-拟合模型-5" class="nav-link" data-scroll-target="#%E6%8B%9F%E5%90%88%E6%A8%A1%E5%9E%8B-5">6.2 拟合模型</a></li>
  <li><a href="#%E6%9F%A5%E7%9C%8B%E6%8B%9F%E5%90%88%E6%95%88%E6%9E%9C-4" id="toc-查看拟合效果-4" class="nav-link" data-scroll-target="#%E6%9F%A5%E7%9C%8B%E6%8B%9F%E5%90%88%E6%95%88%E6%9E%9C-4">6.3 查看拟合效果</a></li>
  <li><a href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-4" id="toc-交叉验证-4" class="nav-link" data-scroll-target="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-4">6.4 交叉验证</a></li>
  </ul>
</li>
  <li><a href="#%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5" id="toc-稀疏矩阵" class="nav-link" data-scroll-target="#%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5">7 稀疏矩阵</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content"><section id="介绍" class="level2"><h2 class="anchored" data-anchor-id="介绍">1 介绍</h2>
<p><code>glmnet</code> 包解决了一下问题（目标函数） <span class="math display">\[
\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} w_i l(y_i,\beta_0+\beta^T x_i) + \lambda\left[(1-\alpha)||\beta||_2^2/2 + \alpha ||\beta||_1\right],
\]</span> #### 1.1 glmnet包安装</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html">install.packages</a></span><span class="op">(</span><span class="st">"glmnet"</span>, repos <span class="op">=</span> <span class="st">"http://cran.us.r-project.org"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="快速开始" class="level2"><h2 class="anchored" data-anchor-id="快速开始">2 快速开始</h2>
<p>这节介绍<code>glmnet</code>包中的主要函数以及它们的一般用法，对常用函数的输入参数以及输出结果做简要的说明。</p>
<section id="加载glmnet包" class="level4"><h4 class="anchored" data-anchor-id="加载glmnet包">2.1 加载glmnet包</h4>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu">glmnet</a></span><span class="op">)</span><span class="co"># 加载glmnet包</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>以线性回归为例，来说明<code>glmnet</code>包的用法。</p>
</section><section id="准备数据" class="level4"><h4 class="anchored" data-anchor-id="准备数据">2.2 准备数据</h4>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">QuickStartExample</span><span class="op">)</span><span class="co">#x为100*20的矩阵 ,y为100 * 1的矩阵。</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">QuickStartExample</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">QuickStartExample</span><span class="op">$</span><span class="va">y</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>该命令R数据存档中加载输入矩阵<code>x</code>和响应向量<code>y</code>。 <code>x</code>为<code>100*20</code>的矩阵 ,<code>y</code>为<code>100 * 1</code>的矩阵。</p>
</section><section id="拟合模型" class="level4"><h4 class="anchored" data-anchor-id="拟合模型">2.3 拟合模型</h4>
<p>数据有了，我们就可以调用包中与之同名的<code>glmnet</code>函数来做线性回归了：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>这里生成的结果 “fit”是类的对象<code>glmnet</code>，包含拟合模型的所有相关信息。不鼓励用户直接提取组件（像list那样提取）。推荐使用各种方法<code>plot</code>，<code>print</code>，<code>coef</code>和<code>predict</code>提取信息，这样能够使我们更优雅执行这些任务。</p>
</section><section id="模型对象的可视化" class="level4"><h4 class="anchored" data-anchor-id="模型对象的可视化">2.4 模型对象的可视化</h4>
<p>采用<code>plot</code>函数对拟合出的模型系数进行可视化：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># label = T，可以显示变量的标签。</span></span>
<span><span class="co"># 参数xvar = c("norm", "lambda", "dev")</span></span>
<span><span class="co"># norm（默认）:  显示系数值和L1范数之间的变化关系</span></span>
<span><span class="co"># lambda： 显示系数值和对数lambda之间的变化关系</span></span>
<span><span class="co"># dev : 显示系数值如何随解释偏差百分比（dev）之间的变化关系</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span>,label <span class="op">=</span> <span class="cn">T</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>上图中，每一条曲线代表一个变量的系数。Y轴是回归系数的值，X轴是L1范数，图中上方有另一条x轴，其数值表示模型的特征数，</p>
</section><section id="模型对象信息的提取" class="level4"><h4 class="anchored" data-anchor-id="模型对象信息的提取">2.5 模型对象信息的提取</h4>
<p>回到我们的拟合结果<code>fit</code>。作为一个 R 对象，我们可以把它当作很多函数的输入。比如说，我们可以查看详细的拟合结果：</p>
<div class="cell" height="4">
<details><summary>Show the code</summary><div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  glmnet(x = x, y = y) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;    Df  %Dev  Lambda</span></span>
<span><span class="co">#&gt; 1   0  0.00 1.63100</span></span>
<span><span class="co">#&gt; 2   2  5.53 1.48600</span></span>
<span><span class="co">#&gt; 3   2 14.59 1.35400</span></span>
<span><span class="co">#&gt; 4   2 22.11 1.23400</span></span>
<span><span class="co">#&gt; 5   2 28.36 1.12400</span></span>
<span><span class="co">#&gt; 6   2 33.54 1.02400</span></span>
<span><span class="co">#&gt; 7   4 39.04 0.93320</span></span>
<span><span class="co">#&gt; 8   5 45.60 0.85030</span></span>
<span><span class="co">#&gt; 9   5 51.54 0.77470</span></span>
<span><span class="co">#&gt; 10  6 57.35 0.70590</span></span>
<span><span class="co">#&gt; 11  6 62.55 0.64320</span></span>
<span><span class="co">#&gt; 12  6 66.87 0.58610</span></span>
<span><span class="co">#&gt; 13  6 70.46 0.53400</span></span>
<span><span class="co">#&gt; 14  6 73.44 0.48660</span></span>
<span><span class="co">#&gt; 15  7 76.21 0.44330</span></span>
<span><span class="co">#&gt; 16  7 78.57 0.40400</span></span>
<span><span class="co">#&gt; 17  7 80.53 0.36810</span></span>
<span><span class="co">#&gt; 18  7 82.15 0.33540</span></span>
<span><span class="co">#&gt; 19  7 83.50 0.30560</span></span>
<span><span class="co">#&gt; 20  7 84.62 0.27840</span></span>
<span><span class="co">#&gt; 21  7 85.55 0.25370</span></span>
<span><span class="co">#&gt; 22  7 86.33 0.23120</span></span>
<span><span class="co">#&gt; 23  8 87.06 0.21060</span></span>
<span><span class="co">#&gt; 24  8 87.69 0.19190</span></span>
<span><span class="co">#&gt; 25  8 88.21 0.17490</span></span>
<span><span class="co">#&gt; 26  8 88.65 0.15930</span></span>
<span><span class="co">#&gt; 27  8 89.01 0.14520</span></span>
<span><span class="co">#&gt; 28  8 89.31 0.13230</span></span>
<span><span class="co">#&gt; 29  8 89.56 0.12050</span></span>
<span><span class="co">#&gt; 30  8 89.76 0.10980</span></span>
<span><span class="co">#&gt; 31  9 89.94 0.10010</span></span>
<span><span class="co">#&gt; 32  9 90.10 0.09117</span></span>
<span><span class="co">#&gt; 33  9 90.23 0.08307</span></span>
<span><span class="co">#&gt; 34  9 90.34 0.07569</span></span>
<span><span class="co">#&gt; 35 10 90.43 0.06897</span></span>
<span><span class="co">#&gt; 36 11 90.53 0.06284</span></span>
<span><span class="co">#&gt; 37 11 90.62 0.05726</span></span>
<span><span class="co">#&gt; 38 12 90.70 0.05217</span></span>
<span><span class="co">#&gt; 39 15 90.78 0.04754</span></span>
<span><span class="co">#&gt; 40 16 90.86 0.04331</span></span>
<span><span class="co">#&gt; 41 16 90.93 0.03947</span></span>
<span><span class="co">#&gt; 42 16 90.98 0.03596</span></span>
<span><span class="co">#&gt; 43 17 91.03 0.03277</span></span>
<span><span class="co">#&gt; 44 17 91.07 0.02985</span></span>
<span><span class="co">#&gt; 45 18 91.11 0.02720</span></span>
<span><span class="co">#&gt; 46 18 91.14 0.02479</span></span>
<span><span class="co">#&gt; 47 19 91.17 0.02258</span></span>
<span><span class="co">#&gt; 48 19 91.20 0.02058</span></span>
<span><span class="co">#&gt; 49 19 91.22 0.01875</span></span>
<span><span class="co">#&gt; 50 19 91.24 0.01708</span></span>
<span><span class="co">#&gt; 51 19 91.25 0.01557</span></span>
<span><span class="co">#&gt; 52 19 91.26 0.01418</span></span>
<span><span class="co">#&gt; 53 19 91.27 0.01292</span></span>
<span><span class="co">#&gt; 54 19 91.28 0.01178</span></span>
<span><span class="co">#&gt; 55 19 91.29 0.01073</span></span>
<span><span class="co">#&gt; 56 19 91.29 0.00978</span></span>
<span><span class="co">#&gt; 57 19 91.30 0.00891</span></span>
<span><span class="co">#&gt; 58 19 91.30 0.00812</span></span>
<span><span class="co">#&gt; 59 19 91.31 0.00739</span></span>
<span><span class="co">#&gt; 60 19 91.31 0.00674</span></span>
<span><span class="co">#&gt; 61 19 91.31 0.00614</span></span>
<span><span class="co">#&gt; 62 20 91.31 0.00559</span></span>
<span><span class="co">#&gt; 63 20 91.31 0.00510</span></span>
<span><span class="co">#&gt; 64 20 91.31 0.00464</span></span>
<span><span class="co">#&gt; 65 20 91.32 0.00423</span></span>
<span><span class="co">#&gt; 66 20 91.32 0.00386</span></span>
<span><span class="co">#&gt; 67 20 91.32 0.00351</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>每一行代表了一个模型 ,它从左到右显示非零系数的个数（<code>Df</code>），模型所解释的偏差的百分比（<code>%dev</code>）和λ的值（<code>Lambda</code>） （注意岭回归中列<code>Df</code>的值是不会变的）</p>
<p>通过<code>coef</code>来提取模型的系数：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 参数s：指定lambda的值，可以是一个向量，则提取多个模型的系数，每一列对应一个模型的系数</span></span>
<span><span class="co"># 参数complete: 逻辑值,表示是否应该返回全系数向量.</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fit</span>,s<span class="op">=</span><span class="fl">0.1</span>,exact<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; 21 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                       s1</span></span>
<span><span class="co">#&gt; (Intercept)  0.150928072</span></span>
<span><span class="co">#&gt; V1           1.320597195</span></span>
<span><span class="co">#&gt; V2           .          </span></span>
<span><span class="co">#&gt; V3           0.675110234</span></span>
<span><span class="co">#&gt; V4           .          </span></span>
<span><span class="co">#&gt; V5          -0.817411518</span></span>
<span><span class="co">#&gt; V6           0.521436671</span></span>
<span><span class="co">#&gt; V7           0.004829335</span></span>
<span><span class="co">#&gt; V8           0.319415917</span></span>
<span><span class="co">#&gt; V9           .          </span></span>
<span><span class="co">#&gt; V10          .          </span></span>
<span><span class="co">#&gt; V11          0.142498519</span></span>
<span><span class="co">#&gt; V12          .          </span></span>
<span><span class="co">#&gt; V13          .          </span></span>
<span><span class="co">#&gt; V14         -1.059978702</span></span>
<span><span class="co">#&gt; V15          .          </span></span>
<span><span class="co">#&gt; V16          .          </span></span>
<span><span class="co">#&gt; V17          .          </span></span>
<span><span class="co">#&gt; V18          .          </span></span>
<span><span class="co">#&gt; V19          .          </span></span>
<span><span class="co">#&gt; V20         -1.021873704</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>用<code>coef</code>来提取模型的系数,参数采用的是<code>s</code> 而不是<code>lambda</code>,—同样在<code>predict</code>函数中一样的道理,eg:</p>
</section><section id="预测" class="level4"><h4 class="anchored" data-anchor-id="预测">2.6 预测</h4>
<p>预测采用<code>predict</code>函数，参数<code>newx</code>用来设置输入数据，<code>s</code>用来设置<span class="math inline">\(\lambda\)</span>的值：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">nx</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10</span><span class="op">*</span><span class="fl">20</span><span class="op">)</span>,<span class="fl">10</span>,<span class="fl">20</span><span class="op">)</span></span>
<span><span class="co">#predict函数与coef函数相比多了一些参数的设置，参数newx设置待预测的输入数据集，以及tpye参数选项</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit</span>,newx<span class="op">=</span><span class="va">nx</span>,s<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>,<span class="fl">0.05</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;               s1         s2</span></span>
<span><span class="co">#&gt;  [1,]  2.4510228  2.5445311</span></span>
<span><span class="co">#&gt;  [2,]  3.7715402  3.9847592</span></span>
<span><span class="co">#&gt;  [3,]  0.2998023  0.3619383</span></span>
<span><span class="co">#&gt;  [4,]  0.6083807  0.5341408</span></span>
<span><span class="co">#&gt;  [5,]  1.3505651  1.2295975</span></span>
<span><span class="co">#&gt;  [6,] -1.4567610 -1.5414550</span></span>
<span><span class="co">#&gt;  [7,] -1.8655189 -2.1116984</span></span>
<span><span class="co">#&gt;  [8,]  3.2607369  3.4219932</span></span>
<span><span class="co">#&gt;  [9,]  2.0913141  2.1585520</span></span>
<span><span class="co">#&gt; [10,] -1.1195637 -1.1657079</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="交叉验证" class="level4"><h4 class="anchored" data-anchor-id="交叉验证">2.7 交叉验证</h4>
<p><code>glmnet</code>提供了一系列的模型可供选择，而在大多数情况下我们需要从中挑选出一个最合适的来用就可以了。这时可以通过交叉验证的方法来筛选最优的λ值了，<code>cv.glmnet</code>函数实现了这一功能。 也支持绘图和预测方法。</p>
<p>继续沿用之前的样本数据，调用<code>cv.glmnet</code>函数：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>可以看到，<code>cv.glmnet</code>返回的结果是一个<code>cv.glmnet</code>类的对象，该对象的类型和<code>glmnet</code>函数返回的结果一样，它们本质上都是R中的list。 不鼓励直接提取信息，推荐使用各种函数提取.</p>
<p>我们用可视化的图形来展示<code>cv.glmnet</code>的结果：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>从图中可以看到MSE是如何随着lambda的不同取值而变化的。红色的散点为交叉验证的散点图，横轴为logλ，纵轴为均方误差，每个点的标准偏差上界和下界也画出来了。图的顶部字数表示非零系数的个数，第一条垂直线对应的是lambda.min的值，它是交叉验证提取出的最优值，第二条（从左往右看）是lambda.lse属性的值，它对应了距离lambda.min一个标准误差的值，并产生了一个更为正则化的模型 （<code>lambda.1se</code>为离最小均方误差一倍标准差的λ值。 ）</p>
<p>最优的λ 值可以直接采用如下命令来提取：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.min</span></span>
<span><span class="co">#&gt; [1] 0.06896889</span></span>
<span><span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.1se</span></span>
<span><span class="co">#&gt; [1] 0.1748613</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>用<code>coef</code>函数来提取回归模型的系数：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">cvfit</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="co">#&gt; 21 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                       s1</span></span>
<span><span class="co">#&gt; (Intercept)  0.147927056</span></span>
<span><span class="co">#&gt; V1           1.337393911</span></span>
<span><span class="co">#&gt; V2           .          </span></span>
<span><span class="co">#&gt; V3           0.704086481</span></span>
<span><span class="co">#&gt; V4           .          </span></span>
<span><span class="co">#&gt; V5          -0.842853150</span></span>
<span><span class="co">#&gt; V6           0.549403480</span></span>
<span><span class="co">#&gt; V7           0.032703914</span></span>
<span><span class="co">#&gt; V8           0.342430521</span></span>
<span><span class="co">#&gt; V9           .          </span></span>
<span><span class="co">#&gt; V10          0.001206608</span></span>
<span><span class="co">#&gt; V11          0.178995989</span></span>
<span><span class="co">#&gt; V12          .          </span></span>
<span><span class="co">#&gt; V13          .          </span></span>
<span><span class="co">#&gt; V14         -1.079993473</span></span>
<span><span class="co">#&gt; V15          .          </span></span>
<span><span class="co">#&gt; V16          .          </span></span>
<span><span class="co">#&gt; V17          .          </span></span>
<span><span class="co">#&gt; V18          .          </span></span>
<span><span class="co">#&gt; V19          .          </span></span>
<span><span class="co">#&gt; V20         -1.061382444</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>可以看到回归模型的系数是采用稀疏矩阵的形式来存储的。由于计算出的模型系数经常是稀疏的，这时采用稀疏矩阵的方式来存储和计算更有效率。如果你不习惯稀疏矩阵的输出形式，可以用<code><a href="https://rdrr.io/r/base/matrix.html">as.matrix()</a></code>将其转化为传统的矩阵形式。</p>
<p>预测同<code>glmnet</code>，直接采用<code>predict</code>泛型函数即可：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="co">#&gt;      lambda.min</span></span>
<span><span class="co">#&gt; [1,] -1.3626977</span></span>
<span><span class="co">#&gt; [2,]  2.5736774</span></span>
<span><span class="co">#&gt; [3,]  0.5767335</span></span>
<span><span class="co">#&gt; [4,]  2.0062604</span></span>
<span><span class="co">#&gt; [5,]  1.5410061</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>自此，<code>glmnet</code>的入门介绍完了，你可以用来他做一些基本的回归模型了。</p>
<p>接下来，我们对<code>glmnet</code>包进行更为深入的介绍。</p>
</section></section><section id="线性回归" class="level2"><h2 class="anchored" data-anchor-id="线性回归">3 线性回归</h2>
<p><code>glmnet</code>中的线性回归主要包含两类。一定是高斯簇<code>gaussian</code>，还有一类是多响应高斯簇<code>mgaussian</code>。我们依次介绍：</p>
<section id="高斯簇" class="level3"><h3 class="anchored" data-anchor-id="高斯簇">3.1 高斯簇</h3>
<p><code>gaussian</code> 是<code>glmnet</code>函数中的默认函数簇，它本质上是带正则项的多元线性回归的估计问题。</p>
<section id="优化目标" class="level4"><h4 class="anchored" data-anchor-id="优化目标">3.1.1 优化目标</h4>
<p>优化的目标函数如下：（高斯族采用的是平方损失函数） <span class="math display">\[
\min_{(\beta_0, \beta) \in \mathbb{R}^{p+1}}\frac{1}{2N} \sum_{i=1}^N (y_i -\beta_0-x_i^T \beta)^2+\lambda \left[ \dfrac{1}{2}(1-\alpha)||\beta||_2^2 + \alpha||\beta||_1\right],
\]</span> 其中 <span class="math inline">\(\lambda \geq 0\)</span> 是模型复杂度参数 ;<span class="math inline">\(0 \leq \alpha \leq 1\)</span> ，当<span class="math inline">\(\alpha = 0\)</span> 时为岭回归，当<span class="math inline">\(\alpha = 1\)</span>为lasso，在<span class="math inline">\(0 &lt;\alpha &lt; 1\)</span>则为两者的折中.</p>
</section><section id="glmnet参数设置" class="level4"><h4 class="anchored" data-anchor-id="glmnet参数设置">3.1.2 glmnet参数设置</h4>
<p><code>glmnet</code>提供了很多参数可以供我们选择。下面介绍一些常用的参数设置：</p>
<ul>
<li>
<code>alpha</code>之前介绍过，它是弹性网的参数，取值范围是[0, 1], (且只能一个一个取，不能为向量)</li>
<li>
<code>weights</code>配置观测的权重。默认每个观测的权重取值均为1。</li>
<li>
<code>nlambda</code>默认值是100。(系统自动挑选 100 个不同的 λ 值，拟合出 100 个系数不同的模型 ）</li>
<li>
<code>lambda</code>一般是程序自动构建，也可以自己定义（可以是向量）。</li>
<li>
<code>standardize</code>表示在拟合模型前，<code>x</code>变量是否需要标准化。默认<code>standardize=TRUE</code>。</li>
</ul>
<p>更多参数设置参考帮助文档<code><a href="https://glmnet.stanford.edu/reference/glmnet.html">help(glmnet)</a></code>。</p>
<p>我们用下面的例子来看看这些参数的用法： 还是用原来的样本数据，不同的是取α = 0.2（接近岭回归的正则项），设置观测的权重以及 λ序列的数量：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, alpha <span class="op">=</span> <span class="fl">0.2</span>, weights <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">50</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">50</span><span class="op">)</span><span class="op">)</span>, nlambda <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>用<code>print</code>函数打印结果：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:  glmnet(x = x, y = y, weights = c(rep(1, 50), rep(2, 50)), alpha = 0.2,      nlambda = 20) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;    Df  %Dev Lambda</span></span>
<span><span class="co">#&gt; 1   0  0.00 7.9390</span></span>
<span><span class="co">#&gt; 2   4 17.89 4.8890</span></span>
<span><span class="co">#&gt; 3   7 44.45 3.0110</span></span>
<span><span class="co">#&gt; 4   7 65.67 1.8540</span></span>
<span><span class="co">#&gt; 5   8 78.50 1.1420</span></span>
<span><span class="co">#&gt; 6   9 85.39 0.7033</span></span>
<span><span class="co">#&gt; 7  10 88.67 0.4331</span></span>
<span><span class="co">#&gt; 8  11 90.25 0.2667</span></span>
<span><span class="co">#&gt; 9  14 91.01 0.1643</span></span>
<span><span class="co">#&gt; 10 17 91.38 0.1012</span></span>
<span><span class="co">#&gt; 11 17 91.54 0.0623</span></span>
<span><span class="co">#&gt; 12 17 91.60 0.0384</span></span>
<span><span class="co">#&gt; 13 19 91.63 0.0236</span></span>
<span><span class="co">#&gt; 14 20 91.64 0.0146</span></span>
<span><span class="co">#&gt; 15 20 91.64 0.0090</span></span>
<span><span class="co">#&gt; 16 20 91.65 0.0055</span></span>
<span><span class="co">#&gt; 17 20 91.65 0.0034</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>打印结果之前已做过说明，这里不再赘述。可以看到这里λ并没有达到预设的20。这是因为在偏差解释率达到0.999或者其变化小于10e-5时计算就会终止。而这些预设的计算终止条件可以通过<code>glmnet.control</code>来设置，详见<code><a href="https://glmnet.stanford.edu/reference/glmnet.control.html">help(glmnet.control)</a></code>。</p>
<p>注意，可以设置<code>digits</code>选项可用于指定打印输出中的有效数字</p>
</section><section id="plot参数设置" class="level4"><h4 class="anchored" data-anchor-id="plot参数设置">3.1.3 plot参数设置</h4>
<p>Y轴为模型的系数值。</p>
<p><code>plot</code>函数可以用<code>xvar</code>来定义X轴的度量，有三种选项：</p>
<ul>
<li>“norm” 表示系数的L1-范数(默认)，显示系数值和L1范数之间的变化关系</li>
<li>“lambda” 表示对数lambda值，显示系数值和对数lambda之间的变化关系</li>
<li>“dev” 表示偏差解释率，显示系数值如何随解释偏差百分比（dev）之间的变化关系</li>
</ul>
<p>在<code>plot</code>函数中添加参数<code>label = TRUE</code>可以显示变量的标签</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/layout.html">layout</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span>,<span class="fl">3</span><span class="op">)</span>,<span class="fl">1</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span>, xvar <span class="op">=</span> <span class="st">"norm"</span>, label <span class="op">=</span> <span class="cn">TRUE</span>,main<span class="op">=</span><span class="st">'nrom\n'</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span>, xvar <span class="op">=</span> <span class="st">"lambda"</span>, label <span class="op">=</span> <span class="cn">TRUE</span>,main<span class="op">=</span><span class="st">'lambda\n'</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span>, xvar <span class="op">=</span> <span class="st">"dev"</span>, label <span class="op">=</span> <span class="cn">TRUE</span>,main<span class="op">=</span><span class="st">'dev\n'</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>每一条曲线代表一个变量的系数。Y轴是回归系数的值，X轴是L1范数(默认)，图中上方有另一条x轴，其数值表示模型的特征数，</p>
</section><section id="coef参数设置" class="level4"><h4 class="anchored" data-anchor-id="coef参数设置">3.1.4 coef参数设置</h4>
<p>coef函数中最常用的两个参数为:</p>
<ul>
<li>
<code>s</code> 指定λ值</li>
<li>
<code>complete</code> 表示是否应该返回全系数向量.</li>
</ul>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/any.html">any</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">lambda</span> <span class="op">==</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] FALSE</span></span>
<span><span class="va">coef.exact</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fit</span>, s <span class="op">=</span> <span class="fl">0.5</span>, complete <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">coef.apprx</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fit</span>, s <span class="op">=</span> <span class="fl">0.5</span>, complete <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu">cbind2</span><span class="op">(</span><span class="va">coef.exact</span>, <span class="va">coef.apprx</span><span class="op">)</span></span>
<span><span class="co">#&gt; 21 x 2 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                       s1           s1</span></span>
<span><span class="co">#&gt; (Intercept)  0.199098747  0.199098747</span></span>
<span><span class="co">#&gt; V1           1.174650452  1.174650452</span></span>
<span><span class="co">#&gt; V2           .            .          </span></span>
<span><span class="co">#&gt; V3           0.531934651  0.531934651</span></span>
<span><span class="co">#&gt; V4           .            .          </span></span>
<span><span class="co">#&gt; V5          -0.760959480 -0.760959480</span></span>
<span><span class="co">#&gt; V6           0.468209413  0.468209413</span></span>
<span><span class="co">#&gt; V7           0.061926756  0.061926756</span></span>
<span><span class="co">#&gt; V8           0.380301491  0.380301491</span></span>
<span><span class="co">#&gt; V9           .            .          </span></span>
<span><span class="co">#&gt; V10          .            .          </span></span>
<span><span class="co">#&gt; V11          0.143260991  0.143260991</span></span>
<span><span class="co">#&gt; V12          .            .          </span></span>
<span><span class="co">#&gt; V13          .            .          </span></span>
<span><span class="co">#&gt; V14         -0.911207368 -0.911207368</span></span>
<span><span class="co">#&gt; V15          .            .          </span></span>
<span><span class="co">#&gt; V16          .            .          </span></span>
<span><span class="co">#&gt; V17          .            .          </span></span>
<span><span class="co">#&gt; V18          0.009196628  0.009196628</span></span>
<span><span class="co">#&gt; V19          .            .          </span></span>
<span><span class="co">#&gt; V20         -0.863117051 -0.863117051</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>结论： 当<code>exact</code>选取不同的参数时，提取的系数也存在一定程度的差异，但差距不大。没有特别要求的话，使用线性插值得到的结果已经够用了。</p>
</section><section id="predict参数设置" class="level4"><h4 class="anchored" data-anchor-id="predict参数设置">3.1.5 predict参数设置</h4>
<p><code>predict</code>函数与<code>coef</code>函数相比多了一些参数的设置：<code>newx</code>是待预测的输入数据集。</p>
<p><code>type</code>有多个选项可供选择：</p>
<ul>
<li>“link” 给出预测值</li>
<li>“response” 对于gaussian簇，同“link”</li>
<li>“coefficients” 计算给定<code>s</code>下的系数矩阵</li>
<li>“nonzero” list对象，存储每个<code>s</code>下非0系数对应的下标</li>
</ul>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span>, type <span class="op">=</span> <span class="st">"response"</span>, s <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt;              s1</span></span>
<span><span class="co">#&gt; [1,] -0.9802591</span></span>
<span><span class="co">#&gt; [2,]  2.2992453</span></span>
<span><span class="co">#&gt; [3,]  0.6010886</span></span>
<span><span class="co">#&gt; [4,]  2.3572668</span></span>
<span><span class="co">#&gt; [5,]  1.7520421</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>上述命令表示在λ = 0.05时计算<code>x</code>头5条观测的预测值。这里的<code>s</code>可以是一个向量，当<code>s</code>是一个多数值向量时，预测值则为一个矩阵。</p>
</section><section id="交叉验证-1" class="level4"><h4 class="anchored" data-anchor-id="交叉验证-1">3.1.6 交叉验证</h4>
<section id="普通计算" class="level5"><h5 class="anchored" data-anchor-id="普通计算">3.1.6.1 普通计算</h5>
<p>这小节对<code>cv.glmnet</code>函数的参数做简要说明：</p>
<ul>
<li>
<code>nfolds</code> – 交叉验证数据集划分的份数</li>
<li>
<code>foldid</code> – 自定义划分数据</li>
<li>
<code>type.measure</code> – 定义交叉验证的损失函数，“deviance”和“mse”用的是平方损失，“mae”用的是平均绝对损失</li>
</ul>
<p>举一个列子：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 做20重交叉验证，采用平均绝对损失</span></span>
<span><span class="va">cvfit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, type.measure <span class="op">=</span> <span class="st">"mse"</span>, nfolds <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="并行计算" class="level5"><h5 class="anchored" data-anchor-id="并行计算">3.1.6.2 并行计算</h5>
<p><code>cv.glmnet</code>也支持并行计算，不过要使其工作，用户必须加载<code>doMC</code>并注册并行数量. 在这里给出一个简单的比较示例。 (不过很遗憾，win不能用)</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">require</a></span><span class="op">(</span><span class="va">doMC</span><span class="op">)</span> <span class="co"># win不能用,可以下载下来，但是不能平行计算。</span></span>
<span><span class="co"># install.packages("doMC", repos="http://R-Forge.R-project.org")</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/doMC/man/registerDoMC.html">registerDoMC</a></span><span class="op">(</span>cores<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1e4</span> <span class="op">*</span> <span class="fl">200</span><span class="op">)</span>, <span class="fl">1e4</span>, <span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">Y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1e4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;    user  system elapsed </span></span>
<span><span class="co">#&gt;   0.704   0.040   0.749</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span><span class="op">(</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span>, parallel <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;    user  system elapsed </span></span>
<span><span class="co">#&gt;   0.963   0.202   0.732</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 看了一下帮助文档 可以改成doParallel 也不能用很奇怪</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/RevolutionAnalytics/doparallel">doParallel</a></span><span class="op">)</span></span>
<span><span class="co"># Windows 可以使用的并行包，但在这里也不能进行并行计算，时间不变</span></span>
<span><span class="va">cl</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html">makeCluster</a></span><span class="op">(</span><span class="fl">6</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/doParallel/man/registerDoParallel.html">registerDoParallel</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/system.time.html">system.time</a></span><span class="op">(</span><span class="op">{</span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span>,parallel<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">}</span><span class="op">)</span></span>
<span><span class="co">#&gt;    user  system elapsed </span></span>
<span><span class="co">#&gt;   0.021   0.003   0.918</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html">stopCluster</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span><span class="co"># 时间也没有明显提高</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>如上所述，并行计算可以显着加速计算过程，尤其是对于大规模问题。</p>
</section><section id="提取最优参数" class="level5"><h5 class="anchored" data-anchor-id="提取最优参数"><strong>3.1.6.3 提取最优参数</strong></h5>
<p>函数 <code>coef</code> 和 <code>predict</code> 处理<code>cv.glmnet</code> 对象和处理 <code>glmnet</code> 对象类似。不过处理<code>cv.glmnet</code>对象时，在指定<span class="math inline">\(s\)</span>参数是可以用两个特殊的字符:<code>lambda.1se</code>和<code>lambda.min</code></p>
<ul>
<li>“lambda.1se”: 为离最小均方误差MSE一倍标准差的<span class="math inline">\(\lambda\)</span>值。</li>
<li>“lambda.min”: 达到最小MSE对应的<span class="math inline">\(\lambda\)</span>值（即 交叉验证提取出的最优值）</li>
</ul>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.min</span></span>
<span><span class="co">#&gt; [1] 0.08307327</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">cvfit</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="co">#&gt; 21 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                      s1</span></span>
<span><span class="co">#&gt; (Intercept)  0.14936467</span></span>
<span><span class="co">#&gt; V1           1.32975267</span></span>
<span><span class="co">#&gt; V2           .         </span></span>
<span><span class="co">#&gt; V3           0.69096092</span></span>
<span><span class="co">#&gt; V4           .         </span></span>
<span><span class="co">#&gt; V5          -0.83122558</span></span>
<span><span class="co">#&gt; V6           0.53669611</span></span>
<span><span class="co">#&gt; V7           0.02005438</span></span>
<span><span class="co">#&gt; V8           0.33193760</span></span>
<span><span class="co">#&gt; V9           .         </span></span>
<span><span class="co">#&gt; V10          .         </span></span>
<span><span class="co">#&gt; V11          0.16239419</span></span>
<span><span class="co">#&gt; V12          .         </span></span>
<span><span class="co">#&gt; V13          .         </span></span>
<span><span class="co">#&gt; V14         -1.07081121</span></span>
<span><span class="co">#&gt; V15          .         </span></span>
<span><span class="co">#&gt; V16          .         </span></span>
<span><span class="co">#&gt; V17          .         </span></span>
<span><span class="co">#&gt; V18          .         </span></span>
<span><span class="co">#&gt; V19          .         </span></span>
<span><span class="co">#&gt; V20         -1.04340741</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="co">#&gt;      lambda.min</span></span>
<span><span class="co">#&gt; [1,] -1.3647490</span></span>
<span><span class="co">#&gt; [2,]  2.5686013</span></span>
<span><span class="co">#&gt; [3,]  0.5705879</span></span>
<span><span class="co">#&gt; [4,]  1.9682289</span></span>
<span><span class="co">#&gt; [5,]  1.4964211</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="数据划分问题" class="level5"><h5 class="anchored" data-anchor-id="数据划分问题">3.1.6.4 数据划分问题</h5>
<p>除了可以设置<code>nfolds</code>来寻找合适的模型外，我们还可以通过<code>foldid</code>设置相同的数据划分来选择最优的α值。</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">foldid</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>,size<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>,replace<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">cv1</span><span class="op">=</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span>,foldid<span class="op">=</span><span class="va">foldid</span>,alpha<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">cv.5</span><span class="op">=</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span>,foldid<span class="op">=</span><span class="va">foldid</span>,alpha<span class="op">=</span><span class="fl">.5</span><span class="op">)</span></span>
<span><span class="va">cv0</span><span class="op">=</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span>,foldid<span class="op">=</span><span class="va">foldid</span>,alpha<span class="op">=</span><span class="fl">0</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>进行对比</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cv1</span><span class="op">)</span>;<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cv.5</span><span class="op">)</span>;<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cv0</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">cv1</span><span class="op">$</span><span class="va">lambda</span><span class="op">)</span>,<span class="va">cv1</span><span class="op">$</span><span class="va">cvm</span>,pch<span class="op">=</span><span class="fl">19</span>,col<span class="op">=</span><span class="st">"red"</span>,xlab<span class="op">=</span><span class="st">"log(Lambda)"</span>,ylab<span class="op">=</span><span class="va">cv1</span><span class="op">$</span><span class="va">name</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">cv.5</span><span class="op">$</span><span class="va">lambda</span><span class="op">)</span>,<span class="va">cv.5</span><span class="op">$</span><span class="va">cvm</span>,pch<span class="op">=</span><span class="fl">19</span>,col<span class="op">=</span><span class="st">"grey"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">cv0</span><span class="op">$</span><span class="va">lambda</span><span class="op">)</span>,<span class="va">cv0</span><span class="op">$</span><span class="va">cvm</span>,pch<span class="op">=</span><span class="fl">19</span>,col<span class="op">=</span><span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html">legend</a></span><span class="op">(</span><span class="st">"topleft"</span>,legend<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"alpha= 1"</span>,<span class="st">"alpha= .5"</span>,<span class="st">"alpha 0"</span><span class="op">)</span>,pch<span class="op">=</span><span class="fl">19</span>,col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"red"</span>,<span class="st">"grey"</span>,<span class="st">"blue"</span><span class="op">)</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>我们可以看到这里选择lasso(<code>alpha=1</code>)时，模型的均方误差最小。</p>
</section></section><section id="系数上限和下限" class="level4"><h4 class="anchored" data-anchor-id="系数上限和下限">3.1.7 系数上限和下限</h4>
<p>这些是最近添加的功能，可以增强模型的范围。假设我们想要拟合我们的模型，但是要将系数限制为大于-0.7且小于0.5。这可以通过<code>upper.limits</code>和<code>lower.limits</code>参数轻松实现：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb25"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tfit</span><span class="op">=</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span>,lower<span class="op">=</span><span class="op">-</span><span class="fl">.7</span>,upper<span class="op">=</span><span class="fl">.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">tfit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-25-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>这些是相当随意的限制; 通常我们希望系数为正，所以我们只能设置<code>lower.limit</code>为0</p>
<blockquote class="blockquote">
<p>注意,上下限的取值范围 ：upper.limits的值不能小于0，lower.limits的值不能大于0 ,另外，如果想对每一个变量的系数对不同的限定，需要将这里的单点值即标量改为向量的形式就可以了。</p>
</blockquote>
</section><section id="惩罚因子" class="level4"><h4 class="anchored" data-anchor-id="惩罚因子">3.1.8 惩罚因子</h4>
<p>这个参数可以给每一个系数提供一个单独的惩罚因子。该惩罚因子默认是1，它也支持自定义。如果将惩罚因子全部设置成为0的话，相当于就没有惩罚项了。</p>
<p>看看以下公式就一目了然了： <span class="math display">\[
\lambda \sum_{j=1}^p \boldsymbol{v_j} P_\alpha(\beta_j) = \lambda \sum_{j=1}^p \boldsymbol{v_j} \left[ (1-\alpha)\frac{1}{2} \beta_j^2 + \alpha |\beta_j| \right].
\]</span> 这个参数设置选项很有用，假如我们知道了一些先验信息，知道了其中一些变量很重要，需要在建模正则化的同时一直保留这些变量，那么可以把这些变量对应系数的惩罚因子设置为0。</p>
<p>同样用之前的数据，我们把第5、10、15个变量对应的惩罚因子设置为0：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">p.fac</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">20</span><span class="op">)</span></span>
<span><span class="va">p.fac</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">15</span><span class="op">)</span><span class="op">]</span> <span class="op">=</span> <span class="fl">0</span></span>
<span><span class="va">pfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, penalty.factor <span class="op">=</span> <span class="va">p.fac</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">pfit</span>, label <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-26-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>从上图中可以看到，变量5、10、15对应的系数一直都在模型中。</p>
<p>还有一些其它的有用的参数，比如，<code>exclude</code>参数可以用来限制指定的变量入选模型；<code>intercept</code>参数可以用来设定模型是否含有截距项等等。更多设置参考帮助文档<code><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">help(cv.glmnet)</a></code>.</p>
</section><section id="自定义图" class="level4"><h4 class="anchored" data-anchor-id="自定义图">3.1.9 自定义图</h4>
<p>有时，特别是当变量数量很少时，我们希望将变量标签添加到绘图中，而不是用变量的所在数据集中的下标。 如下：简单生成一组数据，拟合一个glmnet模型 ，并画出图</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">101</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span>,<span class="fl">100</span>,<span class="fl">10</span><span class="op">)</span></span>
<span><span class="va">y</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">vn</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"var"</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span> </span>
<span><span class="va">fit</span><span class="op">=</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-27-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>然而我们想要的是用变量名称标记曲线 ，如下：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mar<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4.5</span>,<span class="fl">4.5</span>,<span class="fl">1</span>,<span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">vnat</span><span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">vnat</span><span class="op">=</span><span class="va">vnat</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span>,<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">vnat</span><span class="op">)</span><span class="op">]</span> <span class="co"># remove the intercept, and get the coefficients at the end of the path</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span><span class="fl">4</span>, at<span class="op">=</span><span class="va">vnat</span>,line<span class="op">=</span><span class="op">-</span><span class="fl">.5</span>,label<span class="op">=</span><span class="va">vn</span>,las<span class="op">=</span><span class="fl">1</span>,tick<span class="op">=</span><span class="cn">FALSE</span>, cex.axis<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section></section><section id="多响应高斯簇" class="level3"><h3 class="anchored" data-anchor-id="多响应高斯簇">3.2 多响应高斯簇</h3>
<p>多响应高斯簇模型的估计需要在<code>glmnet</code>函数中设置<code>family = "mgaussian"</code>。与以上单变量响应模型类似，它只是响应变量增多了，我们通常称之为“多任务学习”问题。虽然响应变量增多了，但是建模时所选择的自变量是完全一样的，只是待估系数不同而已。</p>
<p>很显然，模型的因变量不再是一个向量形式，而是一个二维矩阵，这时估计出的系数也会是一个矩阵，先看看多响应高斯簇模型解决的问题： <span class="math display">\[
\min_{(\beta_0, \beta) \in \mathbb{R}^{(p+1)\times K}}\frac{1}{2N} \sum_{i=1}^N ||y_i -\beta_0-\beta^T x_i||^2_F+\lambda \left[ (1-\alpha)||\beta||_F^2/2 + \alpha\sum_{j=1}^p||\beta_j||_2\right].
\]</span> 这里的βj是<span class="math inline">\(p\times K\)</span>维的系数矩阵<span class="math inline">\(\beta\)</span>的第j行。</p>
<section id="载入演示数据" class="level4"><h4 class="anchored" data-anchor-id="载入演示数据">3.2.1 载入演示数据</h4>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">MultiGaussianExample</span><span class="op">)</span><span class="co"># 产生x,y两个矩阵，x的维度100*20 ,y的维度100 * 4。</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">MultiGaussianExample</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">MultiGaussianExample</span><span class="op">$</span><span class="va">y</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="拟合模型-1" class="level4"><h4 class="anchored" data-anchor-id="拟合模型-1">3.2.2 拟合模型</h4>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">mfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"mgaussian"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>多响应高斯模型与单响应高斯模型的大部分参数设置相同，如<code>alpha</code>,<code>weights</code>,<code>nlambda</code>,<code>standardize</code>。<strong>但是<code>mgaussian</code>簇有一个额外的参数<code>standardize.response</code>，它可以用来给响应变量做标准化，默认为<code>FALSE</code></strong>。</p>
</section><section id="查看拟合效果" class="level4"><h4 class="anchored" data-anchor-id="查看拟合效果">3.2.3 查看拟合效果</h4>
<p>用<code>plot</code>函数查看系数的变化：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mfit</span>, xvar <span class="op">=</span> <span class="st">"lambda"</span>, label <span class="op">=</span> <span class="cn">TRUE</span>, type.coef <span class="op">=</span> <span class="st">"2norm"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-31-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Show the code</summary><div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mfit</span>, xvar <span class="op">=</span> <span class="st">"lambda"</span>, label <span class="op">=</span> <span class="cn">TRUE</span>, type.coef <span class="op">=</span> <span class="st">"coef"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-31-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-31-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-31-4.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-31-5.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>其中<code>xvar</code>并且<code>label</code>两个参数的设置与单响应的高斯模型一样 。这里的<code>type.coef = "2norm"</code>表示每个变量的系数以二范数的形式展现。默认设置为<code>type.coef = "coef"</code>，这时每个响应变量会展示一张系数变化的图。</p>
</section><section id="预测-1" class="level4"><h4 class="anchored" data-anchor-id="预测-1">3.2.4 预测</h4>
<p>可以通过<code>coef</code>函数提取系数 ，<code>predict</code>函数进行预测。用法和但响应的高斯模型一样，下面看看<code>predict</code>的用法：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">mfit</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span>, s <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.01</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; , , 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              y1         y2         y3       y4</span></span>
<span><span class="co">#&gt; [1,] -4.7106263 -1.1634574  0.6027634 3.740989</span></span>
<span><span class="co">#&gt; [2,]  4.1301735 -3.0507968 -1.2122630 4.970141</span></span>
<span><span class="co">#&gt; [3,]  3.1595229 -0.5759621  0.2607981 2.053976</span></span>
<span><span class="co">#&gt; [4,]  0.6459242  2.1205605 -0.2252050 3.146286</span></span>
<span><span class="co">#&gt; [5,] -1.1791890  0.1056262 -7.3352965 3.248370</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; , , 2</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;              y1         y2         y3       y4</span></span>
<span><span class="co">#&gt; [1,] -4.6415158 -1.2290282  0.6118289 3.779521</span></span>
<span><span class="co">#&gt; [2,]  4.4712843 -3.2529658 -1.2572583 5.266039</span></span>
<span><span class="co">#&gt; [3,]  3.4735228 -0.6929231  0.4684037 2.055574</span></span>
<span><span class="co">#&gt; [4,]  0.7353311  2.2965083 -0.2190297 2.989371</span></span>
<span><span class="co">#&gt; [5,] -1.2759930  0.2892536 -7.8259206 3.205211</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="交叉验证-2" class="level4"><h4 class="anchored" data-anchor-id="交叉验证-2">3.2.5 交叉验证</h4>
<p>同样的交叉验证用<code>cv.glmnet</code>函数：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvmfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"mgaussian"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>画出交叉验证的结果：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb35"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cvmfit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-34-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>想要查看最优的<span class="math inline">\(\lambda\)</span>,,采用如下命令:</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvmfit</span><span class="op">$</span><span class="va">lambda.min</span></span>
<span><span class="co">#&gt; [1] 0.05193158</span></span>
<span><span class="va">cvmfit</span><span class="op">$</span><span class="va">lambda.1se</span></span>
<span><span class="co">#&gt; [1] 0.174054</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>和以前一样，第一个是达到最小均方误差的值，第二个是最正则化模型，其均方误差在最小值的一个标准误差范围内</p>
</section></section></section><section id="逻辑回归" class="level2"><h2 class="anchored" data-anchor-id="逻辑回归">4 逻辑回归</h2>
<p>逻辑回归是分类问题中最常用的模型之一。如果是一个二分类问题，一般假定响应变量服从二项分布，如果是多分类问题，则假定服从多项式分布。</p>
<section id="二项分布逻辑回归" class="level3"><h3 class="anchored" data-anchor-id="二项分布逻辑回归">4.1 二项分布逻辑回归</h3>
<p>假定响应变量的取值为 <span class="math inline">\(\mathcal{G}=\{1,2\}\)</span>.定义 <span class="math inline">\(y_i = I(g_i=1)\)</span>.则有</p>
<p><span class="math display">\[
\mbox{Pr}(G=2|X=x)+\frac{e^{\beta_0+\beta^Tx}}{1+e^{\beta_0+\beta^Tx}}
\]</span> 我们可以两边取对数，改写为如下形式（称为对数似然函数）：</p>
<p><span class="math display">\[
\log\frac{\mbox{Pr}(G=2|X=x)}{\mbox{Pr}(G=1|X=x)}=\beta_0+\beta^Tx
\]</span></p>
<p>这个带惩罚逻辑回归的目标函数的对数似然如下： <span class="math display">\[
\min_{(\beta_0, \beta) \in \mathbb{R}^{p+1}} -\left[\frac{1}{N} \sum_{i=1}^N y_i \cdot (\beta_0 + x_i^T \beta) - \log (1+e^{(\beta_0+x_i^T \beta)})\right] + \lambda \big[ (1-\alpha)||\beta||_2^2/2 + \alpha||\beta||_1\big].
\]</span> 当 <span class="math inline">\(p &gt; N\)</span> 时，逻辑回归常常伴随着退化的困扰 ，当<span class="math inline">\(N\)</span>接近<span class="math inline">\(p\)</span>时，甚至在表现出野蛮的行为 。弹性网惩罚缓解了这些问题。</p>
<section id="载入示例数据集" class="level4"><h4 class="anchored" data-anchor-id="载入示例数据集">4.1.1 载入示例数据集</h4>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">BinomialExample</span><span class="op">)</span><span class="co"># 产生名为x维度为100*30的矩阵 ,名为y长度为100的int向量（0、1向量）</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">BinomialExample</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">BinomialExample</span><span class="op">$</span><span class="va">y</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>这里的输入x与其他分布簇相同，对于二项Logistic回归，响应变量y应该是具有两个级别的因子，或者是计数或比例的两列矩阵</p>
</section><section id="拟合模型-2" class="level4"><h4 class="anchored" data-anchor-id="拟合模型-2">4.1.2 拟合模型</h4>
<p><code>glmnet</code>二项式回归的其他可选参数与高斯族的几乎相同.仅需要把函数簇改为<code>family = "binomial"</code>即可：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="查看拟合效果-1" class="level4"><h4 class="anchored" data-anchor-id="查看拟合效果-1">4.1.3 查看拟合效果</h4>
<p>同样， 我们可以用<code>print</code>和<code>plot</code>函数去查看对象 , 用<code>coef</code>提取特定λ的系数，用<code>predict</code>可以做出预测 .</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span>, xvar <span class="op">=</span> <span class="st">"dev"</span>, label <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-38-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section><section id="预测-2" class="level4"><h4 class="anchored" data-anchor-id="预测-2">4.1.4 预测</h4>
<p>逻辑回归的预测同高斯簇函数的用法有点不同，主要体现在参数<code>type</code>的设置上，详细概括如下：</p>
<ul>
<li>“link” 线性拟合值</li>
<li>“response” 拟合的概率值</li>
<li>“class” 给出计算出的最大概率对应的类的标签</li>
<li>“coefficients” 计算给定<code>s</code>下的系数的估计值</li>
<li>“nonzero” 返回一个list对象，该list包含每一个<code>s</code>对应非零系数的索引</li>
</ul>
<blockquote class="blockquote">
<p>对于“二项式”模型，预测结果仅仅是针对响应变量的第二个水平(“link”, “response”, “coefficients”, “nonzero”) (可以用<code>level</code>函数查看第二级别的类)</p>
</blockquote>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb40"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span>, type <span class="op">=</span> <span class="st">"class"</span>, s <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.05</span>, <span class="fl">0.01</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      s1  s2 </span></span>
<span><span class="co">#&gt; [1,] "0" "0"</span></span>
<span><span class="co">#&gt; [2,] "1" "1"</span></span>
<span><span class="co">#&gt; [3,] "1" "1"</span></span>
<span><span class="co">#&gt; [4,] "0" "0"</span></span>
<span><span class="co">#&gt; [5,] "1" "1"</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="交叉验证-3" class="level4"><h4 class="anchored" data-anchor-id="交叉验证-3">4.1.5 交叉验证</h4>
<p>逻辑回归的<code>cv.glmnet</code>的用法同高斯簇函数，<code>nfolds</code>, <code>weights</code>, <code>lambda</code>,<code>parallel</code>的设置一样，区别主要在<code>type.measure</code>：</p>
<ul>
<li>“mse” 用平方损失</li>
<li>“deviance” 用真实偏差</li>
<li>“mae” 用平均绝对误差</li>
<li>“class” 用误分类率</li>
<li>“auc” ROC曲线的下面积(这个选项仅针对两分类逻辑回归)。是现在最流行的综合考量模型性能的一种参数</li>
</ul>
<p>例如，用误分类率误差为标准做十折交叉验证，代码如下：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, type.measure <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>用<code>plot</code>查看<code>cv.glmnet</code>生成的结果： .</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb42"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-41-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb43"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.min</span> <span class="co">#查看最优的λ值</span></span>
<span><span class="co">#&gt; [1] 0.01116192</span></span>
<span><span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.1se</span></span>
<span><span class="co">#&gt; [1] 0.0310587</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><code>coef</code>和<code>predict</code>与高斯簇类似：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb44"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">cvfit</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span> <span class="co"># 如前所述，此处返回的结果仅适用于响应变量的第二个水平。</span></span>
<span><span class="co">#&gt; 31 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                       s1</span></span>
<span><span class="co">#&gt; (Intercept)  0.219571057</span></span>
<span><span class="co">#&gt; V1           0.127143184</span></span>
<span><span class="co">#&gt; V2           0.773438291</span></span>
<span><span class="co">#&gt; V3          -0.622026677</span></span>
<span><span class="co">#&gt; V4          -1.249153390</span></span>
<span><span class="co">#&gt; V5          -0.236036348</span></span>
<span><span class="co">#&gt; V6          -1.086126631</span></span>
<span><span class="co">#&gt; V7           .          </span></span>
<span><span class="co">#&gt; V8          -0.662605660</span></span>
<span><span class="co">#&gt; V9           0.903895121</span></span>
<span><span class="co">#&gt; V10         -1.662994099</span></span>
<span><span class="co">#&gt; V11         -0.069429691</span></span>
<span><span class="co">#&gt; V12         -0.109197705</span></span>
<span><span class="co">#&gt; V13          .          </span></span>
<span><span class="co">#&gt; V14          .          </span></span>
<span><span class="co">#&gt; V15          .          </span></span>
<span><span class="co">#&gt; V16          0.489302061</span></span>
<span><span class="co">#&gt; V17          .          </span></span>
<span><span class="co">#&gt; V18         -0.123121403</span></span>
<span><span class="co">#&gt; V19         -0.009732698</span></span>
<span><span class="co">#&gt; V20         -0.063913565</span></span>
<span><span class="co">#&gt; V21          .          </span></span>
<span><span class="co">#&gt; V22          0.237278301</span></span>
<span><span class="co">#&gt; V23          0.413516340</span></span>
<span><span class="co">#&gt; V24         -0.040687440</span></span>
<span><span class="co">#&gt; V25          0.746129317</span></span>
<span><span class="co">#&gt; V26         -0.376173275</span></span>
<span><span class="co">#&gt; V27         -0.168082915</span></span>
<span><span class="co">#&gt; V28          0.312045066</span></span>
<span><span class="co">#&gt; V29         -0.254478998</span></span>
<span><span class="co">#&gt; V30          0.157077463</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>As mentioned previously, the results returned here are only for the second level of the factor response.</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb45"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>,<span class="op">]</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="co">#&gt;       lambda.min</span></span>
<span><span class="co">#&gt;  [1,] "0"       </span></span>
<span><span class="co">#&gt;  [2,] "1"       </span></span>
<span><span class="co">#&gt;  [3,] "1"       </span></span>
<span><span class="co">#&gt;  [4,] "0"       </span></span>
<span><span class="co">#&gt;  [5,] "1"       </span></span>
<span><span class="co">#&gt;  [6,] "0"       </span></span>
<span><span class="co">#&gt;  [7,] "0"       </span></span>
<span><span class="co">#&gt;  [8,] "0"       </span></span>
<span><span class="co">#&gt;  [9,] "1"       </span></span>
<span><span class="co">#&gt; [10,] "1"</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section></section><section id="多分类逻辑回归" class="level3"><h3 class="anchored" data-anchor-id="多分类逻辑回归">4.2 多分类逻辑回归</h3>
<p>多分类逻辑回归假定响应变量服从多项式分布, 假定响应变量有K个水平 <span class="math inline">\({\cal G}=\{1,2,\ldots,K\}\)</span>。则有</p>
<p><span class="math display">\[
\mbox{Pr}(G=k|X=x)=\frac{e^{\beta_{0k}+\beta_k^Tx}}{\sum_{\ell=1}^Ke^{\beta_{0\ell}+\beta_\ell^Tx}}.
\]</span></p>
<p><span class="math inline">\({Y}\)</span> 应该是 <span class="math inline">\(N \times K\)</span> 的响应矩阵（把离散变量进行one-hot编码即可） ,那么带弹性网惩罚项的非负对数似然函数如下： <span class="math display">\[
\ell(\{\beta_{0k},\beta_{k}\}_1^K) = -\left[\frac{1}{N} \sum_{i=1}^N \Big(\sum_{k=1}^Ky_{il} (\beta_{0k} + x_i^T \beta_k)- \log \big(\sum_{k=1}^K e^{\beta_{0k}+x_i^T \beta_k}\big)\Big)\right] +\lambda \left[ (1-\alpha)||\beta||_F^2/2 + \alpha\sum_{j=1}^p||\beta_j||_q\right].
\]</span> 这里β是一个<span class="math inline">\(p\times K\)</span>维的系数矩阵 <span class="math inline">\(\beta_k\)</span> 是其中的第<span class="math inline">\(k\)</span>列,表示第<span class="math inline">\(k\)</span>个模型对应模型的系数 , <span class="math inline">\(\beta_j\)</span> 第<span class="math inline">\(j\)</span>行，表示第<span class="math inline">\(j\)</span>个变量前面的系数。</p>
<p>后面的惩罚项 <span class="math inline">\(||\beta_j||_q\)</span>, 有两种情形 <span class="math inline">\(q\in \{1,2\}\)</span>.当q=1时，它是一个lasso惩罚项；当q=2时，它是一个grouped-lasso惩罚项。</p>
<section id="载入示例数据集-1" class="level4"><h4 class="anchored" data-anchor-id="载入示例数据集-1">4.2.1 载入示例数据集</h4>
<p>首先载入数据集：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb46"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">MultinomialExample</span><span class="op">)</span><span class="co"># 产生名为x维度为100*30的矩阵 ,名为y长度为100的数字向量（水平1,2,3组成）训练是内部自动转换</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">MultinomialExample</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">MultinomialExample</span><span class="op">$</span><span class="va">y</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="拟合模型-3" class="level4"><h4 class="anchored" data-anchor-id="拟合模型-3">4.2.2 拟合模型</h4>
<p>多分类逻辑回归的模型拟和二分类逻辑回归类似，只是这里新增加了一个特殊的参数<code>type.multinomial</code>，当<code>type.multinomial = "grouped"</code>时，模型拟合时会让每个变量前面的系数全为0或者全不为零，其实就是对于每个类建立逻辑回归时所用到的变量完全相同。</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb47"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"multinomial"</span>, type.multinomial <span class="op">=</span> <span class="st">"grouped"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="查看拟合效果-2" class="level4"><h4 class="anchored" data-anchor-id="查看拟合效果-2">4.2.3 查看拟合效果</h4>
<p>用<code>plot</code>查看模型拟合结果：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb48"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span>, xvar <span class="op">=</span> <span class="st">"lambda"</span>, label <span class="op">=</span> <span class="cn">TRUE</span>, type.coef <span class="op">=</span> <span class="st">"2norm"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-47-1.png" class="img-fluid" width="672"></p>
</div>
<details><summary>Show the code</summary><div class="sourceCode" id="cb49"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span>, xvar <span class="op">=</span> <span class="st">"lambda"</span>, label <span class="op">=</span> <span class="cn">TRUE</span>, type.coef <span class="op">=</span> <span class="st">"coef"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-47-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-47-3.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-47-4.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>这里<code>xvar</code>和<code>label</code>的使用和之前相同，但是多了一个<code>type.coef</code>选项，这个选项仅适用于对多分类逻辑回归以及多响应变量线性回归，若<code>type.coef = "coef"</code>会用多张图分别展示每个响应变量的系数，若<code>type.coef = "2norm"</code>则会展示系数的L2-范数。</p>
</section><section id="交叉验证和预测" class="level4"><h4 class="anchored" data-anchor-id="交叉验证和预测">4.2.4 交叉验证和预测</h4>
<p>我们同样也可以做交叉验证：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb50"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/RevolutionAnalytics/doparallel">doParallel</a></span><span class="op">)</span></span>
<span><span class="co"># Windows System</span></span>
<span><span class="va">cl</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html">makeCluster</a></span><span class="op">(</span><span class="fl">7</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/doParallel/man/registerDoParallel.html">registerDoParallel</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span></span>
<span><span class="va">cvfit</span><span class="op">=</span><span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family<span class="op">=</span><span class="st">"multinomial"</span>, type.multinomial <span class="op">=</span> <span class="st">"grouped"</span>, parallel <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html">stopCluster</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-48-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>用拟合的模型来预测：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb51"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>,<span class="op">]</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span>, type <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="co">#&gt;       1  </span></span>
<span><span class="co">#&gt;  [1,] "3"</span></span>
<span><span class="co">#&gt;  [2,] "2"</span></span>
<span><span class="co">#&gt;  [3,] "2"</span></span>
<span><span class="co">#&gt;  [4,] "3"</span></span>
<span><span class="co">#&gt;  [5,] "1"</span></span>
<span><span class="co">#&gt;  [6,] "3"</span></span>
<span><span class="co">#&gt;  [7,] "3"</span></span>
<span><span class="co">#&gt;  [8,] "1"</span></span>
<span><span class="co">#&gt;  [9,] "1"</span></span>
<span><span class="co">#&gt; [10,] "2"</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section></section></section><section id="泊松回归" class="level2"><h2 class="anchored" data-anchor-id="泊松回归">5 泊松回归</h2>
<p>泊松回归经常会用到计数模型中，假定其误差满足泊松分布。</p>
<p>经常用其均值的对数来建模：<span class="math inline">\(\log \mu(x) = \beta_0+\beta' x\)</span>.</p>
<p>给定 <span class="math inline">\(\{x_i,y_i\}_1^N\)</span>下的对数似然为: <span class="math display">\[
l(\beta|X, Y) = \sum_{i=1}^N (y_i (\beta_0+\beta' x_i) - e^{\beta_0+\beta^Tx_i}.
\]</span> 于是问题变成优化如下带惩罚的对数似然： <span class="math display">\[
\min_{\beta_0,\beta} -\frac1N l(\beta|X, Y)  + \lambda \left((1-\alpha) \sum_{i=1}^N \beta_i^2/2) +\alpha \sum_{i=1}^N |\beta_i|\right).
\]</span></p>
<section id="加载数据集" class="level3"><h3 class="anchored" data-anchor-id="加载数据集">5.1 加载数据集</h3>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb52"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">PoissonExample</span><span class="op">)</span><span class="co"># 产生名为x维度为500*20的矩阵 ,名为y长度为500的数字向量,全是大于0的数字（泊松函数也是大于0的函数）</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">PoissonExample</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">PoissonExample</span><span class="op">$</span><span class="va">y</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="拟合模型-4" class="level3"><h3 class="anchored" data-anchor-id="拟合模型-4">5.2 拟合模型</h3>
<p>采用<code>glmnet</code>函数，设置<code>family = "poisson"</code>：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb53"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"poisson"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="查看拟合效果-3" class="level3"><h3 class="anchored" data-anchor-id="查看拟合效果-3">5.3 查看拟合效果</h3>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb54"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-52-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section><section id="预测-3" class="level3"><h3 class="anchored" data-anchor-id="预测-3">5.4 预测</h3>
<p>用<code>predict</code>做预测,在参数选项的设置中，主要是<code>type</code>存在一些差异，做出说明如下：</p>
<ul>
<li>“link” 给出线性拟合值</li>
<li>“response” 给出拟合的均值</li>
<li>“coefficients” 计算给定<code>s</code>下的系数，也可以直接用<code>coef</code>函数</li>
<li>“nonzero” 返回一个list对象，该list包含每一个<code>s</code>对应非零系数的索引</li>
</ul>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb55"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fit</span>, s <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; 21 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                      s1</span></span>
<span><span class="co">#&gt; (Intercept)  0.61123371</span></span>
<span><span class="co">#&gt; V1           0.45819758</span></span>
<span><span class="co">#&gt; V2          -0.77060709</span></span>
<span><span class="co">#&gt; V3           1.34015128</span></span>
<span><span class="co">#&gt; V4           0.04350500</span></span>
<span><span class="co">#&gt; V5          -0.20325967</span></span>
<span><span class="co">#&gt; V6           .         </span></span>
<span><span class="co">#&gt; V7           .         </span></span>
<span><span class="co">#&gt; V8           .         </span></span>
<span><span class="co">#&gt; V9           .         </span></span>
<span><span class="co">#&gt; V10          .         </span></span>
<span><span class="co">#&gt; V11          .         </span></span>
<span><span class="co">#&gt; V12          0.01816309</span></span>
<span><span class="co">#&gt; V13          .         </span></span>
<span><span class="co">#&gt; V14          .         </span></span>
<span><span class="co">#&gt; V15          .         </span></span>
<span><span class="co">#&gt; V16          .         </span></span>
<span><span class="co">#&gt; V17          .         </span></span>
<span><span class="co">#&gt; V18          .         </span></span>
<span><span class="co">#&gt; V19          .         </span></span>
<span><span class="co">#&gt; V20          .</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span>, type <span class="op">=</span> <span class="st">"response"</span>, s <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;              s1         s2</span></span>
<span><span class="co">#&gt; [1,]  2.4944232  4.4263365</span></span>
<span><span class="co">#&gt; [2,] 10.3513120 11.0586174</span></span>
<span><span class="co">#&gt; [3,]  0.1179704  0.1781626</span></span>
<span><span class="co">#&gt; [4,]  0.9713412  1.6828778</span></span>
<span><span class="co">#&gt; [5,]  1.1133472  1.9934537</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>我们同样也可以做交叉验证：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb56"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"poisson"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>选项与高斯族几乎相同，除了&nbsp;<code>type.measure</code></p>
<ul>
<li>
<code>cv.glmnet</code>中<code>type.measure</code>的设置：
<ul>
<li>“deviance” 偏差</li>
<li>“mse” 均方误差</li>
<li>“mae” 平均绝对误差</li>
</ul>
</li>
</ul>
<p>绘制<code>cv.glmnet</code>对象。</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb57"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-55-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>提取最优λ对应的模型系数：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb58"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">opt.lam</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.min</span>, <span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.1se</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">cvfit</span>, s <span class="op">=</span> <span class="va">opt.lam</span><span class="op">)</span></span>
<span><span class="co">#&gt; 21 x 2 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;                       s1           s2</span></span>
<span><span class="co">#&gt; (Intercept)  0.070584044  0.200007600</span></span>
<span><span class="co">#&gt; V1           0.609229006  0.571833738</span></span>
<span><span class="co">#&gt; V2          -0.972486782 -0.927099773</span></span>
<span><span class="co">#&gt; V3           1.509004735  1.466409190</span></span>
<span><span class="co">#&gt; V4           0.225598648  0.192138902</span></span>
<span><span class="co">#&gt; V5          -0.328715117 -0.301559295</span></span>
<span><span class="co">#&gt; V6           .            .          </span></span>
<span><span class="co">#&gt; V7          -0.005088443  .          </span></span>
<span><span class="co">#&gt; V8           .            .          </span></span>
<span><span class="co">#&gt; V9           .            .          </span></span>
<span><span class="co">#&gt; V10          0.006071219  .          </span></span>
<span><span class="co">#&gt; V11          .            .          </span></span>
<span><span class="co">#&gt; V12          0.029070537  0.025801372</span></span>
<span><span class="co">#&gt; V13         -0.014882186  .          </span></span>
<span><span class="co">#&gt; V14          0.020864442  .          </span></span>
<span><span class="co">#&gt; V15          .            .          </span></span>
<span><span class="co">#&gt; V16          0.008606587  .          </span></span>
<span><span class="co">#&gt; V17          .            .          </span></span>
<span><span class="co">#&gt; V18          .            .          </span></span>
<span><span class="co">#&gt; V19         -0.023621751  .          </span></span>
<span><span class="co">#&gt; V20          0.011789503  0.009436612</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>可以使用<code>predict</code>进行预测，方法类似，在重复</p>
</section></section><section id="cox模型" class="level2"><h2 class="anchored" data-anchor-id="cox模型">6 Cox模型</h2>
<p>不是很了解。</p>
<p>The Cox proportional hazards model is commonly used for the study of the relationship beteween predictor variables and survival time. In the usual survival analysis framework, we have data of the form <span class="math inline">\((y_1, x_1, \delta_1), \ldots, (y_n, x_n, \delta_n)\)</span> where <span class="math inline">\(y_i\)</span>, the observed time, is a time of failure if <span class="math inline">\(\delta_i\)</span> is 1 or right-censoring if <span class="math inline">\(\delta_i\)</span> is 0. We also let <span class="math inline">\(t_1 &lt; t_2 &lt; \ldots &lt; t_m\)</span> be the increasing list of unique failure times, and <span class="math inline">\(j(i)\)</span> denote the index of the observation failing at time <span class="math inline">\(t_i\)</span>.</p>
<p>The Cox model assumes a semi-parametric form for the hazard <span class="math display">\[
h_i(t) = h_0(t) e^{x_i^T \beta},
\]</span> where <span class="math inline">\(h_i(t)\)</span> is the hazard for patient <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>, <span class="math inline">\(h_0(t)\)</span> is a shared baseline hazard, and <span class="math inline">\(\beta\)</span> is a fixed, length <span class="math inline">\(p\)</span> vector. In the classic setting <span class="math inline">\(n \geq p\)</span>, inference is made via the partial likelihood <span class="math display">\[
L(\beta) = \prod_{i=1}^m \frac{e^{x_{j(i)}^T \beta}}{\sum_{j \in R_i} e^{x_j^T \beta}},
\]</span> where <span class="math inline">\(R_i\)</span> is the set of indices <span class="math inline">\(j\)</span> with <span class="math inline">\(y_j \geq t_i\)</span> (those at risk at time <span class="math inline">\(t_i\)</span>).</p>
<p>Note there is no intercept in the Cox mode (its built into the baseline hazard, and like it, would cancel in the partial likelihood.)</p>
<p>We penalize the negative log of the partial likelihood, just like the other models, with an elastic-net penalty.</p>
<section id="载入数据集" class="level3"><h3 class="anchored" data-anchor-id="载入数据集">6.1 载入数据集</h3>
<p>同样地，我们加载预先生成好的样本数据和响应变量，但是这里需要注意的是，这里采用了生存分析的分析框架，输入数据略有差别。首先，我们加载数据集：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb59"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">CoxExample</span><span class="op">)</span><span class="co"># 产生名为x的矩阵，其维度为1000*30 ，名为y的矩阵，其维度为1000*2</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">CoxExample</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">CoxExample</span><span class="op">$</span><span class="va">y</span></span>
<span><span class="va">y</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>,<span class="op">]</span> <span class="co"># status列表示time列对应下的状态，第一列必须是数值型的时间，第二列参数是逻辑向量，0/1表示死亡与否</span></span>
<span><span class="co">#&gt;            time status</span></span>
<span><span class="co">#&gt; [1,] 1.76877757      1</span></span>
<span><span class="co">#&gt; [2,] 0.54528404      1</span></span>
<span><span class="co">#&gt; [3,] 0.04485918      0</span></span>
<span><span class="co">#&gt; [4,] 0.85032298      0</span></span>
<span><span class="co">#&gt; [5,] 0.61488426      1</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>可以看到加载的数据还是包含自变量x以及响应变量y两部分：x是n×p维的矩阵；不同的是y，y为<span class="math inline">\(n \times 1\)</span>维的矩阵，其中名为<code>time</code>的列是观察时间，名为<code>status</code>的列为该观察时间下对应的状态，0表示生成，1表示死亡。</p>
</section><section id="拟合模型-5" class="level3"><h3 class="anchored" data-anchor-id="拟合模型-5">6.2 拟合模型</h3>
<p>同样用<code>glmnet</code>建模:</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb60"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"cox"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section><section id="查看拟合效果-4" class="level3"><h3 class="anchored" data-anchor-id="查看拟合效果-4">6.3 查看拟合效果</h3>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb61"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-59-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>提取给定 <span class="math inline">\(\lambda\)</span>下对应的系数：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb62"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fit</span>, s <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt; 30 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;               1</span></span>
<span><span class="co">#&gt; V1   0.37693638</span></span>
<span><span class="co">#&gt; V2  -0.09547797</span></span>
<span><span class="co">#&gt; V3  -0.13595972</span></span>
<span><span class="co">#&gt; V4   0.09814146</span></span>
<span><span class="co">#&gt; V5  -0.11437545</span></span>
<span><span class="co">#&gt; V6  -0.38898545</span></span>
<span><span class="co">#&gt; V7   0.24291400</span></span>
<span><span class="co">#&gt; V8   0.03647596</span></span>
<span><span class="co">#&gt; V9   0.34739813</span></span>
<span><span class="co">#&gt; V10  0.03865115</span></span>
<span><span class="co">#&gt; V11  .         </span></span>
<span><span class="co">#&gt; V12  .         </span></span>
<span><span class="co">#&gt; V13  .         </span></span>
<span><span class="co">#&gt; V14  .         </span></span>
<span><span class="co">#&gt; V15  .         </span></span>
<span><span class="co">#&gt; V16  .         </span></span>
<span><span class="co">#&gt; V17  .         </span></span>
<span><span class="co">#&gt; V18  .         </span></span>
<span><span class="co">#&gt; V19  .         </span></span>
<span><span class="co">#&gt; V20  .         </span></span>
<span><span class="co">#&gt; V21  .         </span></span>
<span><span class="co">#&gt; V22  .         </span></span>
<span><span class="co">#&gt; V23  .         </span></span>
<span><span class="co">#&gt; V24  .         </span></span>
<span><span class="co">#&gt; V25  .         </span></span>
<span><span class="co">#&gt; V26  .         </span></span>
<span><span class="co">#&gt; V27  .         </span></span>
<span><span class="co">#&gt; V28  .         </span></span>
<span><span class="co">#&gt; V29  .         </span></span>
<span><span class="co">#&gt; V30  .</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>由于Cox模型不常用于预测，所以没有给出预测的样例 。如果需要，可以参考帮助文件<code><a href="https://glmnet.stanford.edu/reference/predict.glmnet.html">help(predict.glmnet)</a></code>。</p>
</section><section id="交叉验证-4" class="level3"><h3 class="anchored" data-anchor-id="交叉验证-4">6.4 交叉验证</h3>
<p>用<code>cv.glmnet</code>做K折交叉验证时，<code>type.measure</code>的选项仅支持“deviance”：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb63"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, family <span class="op">=</span> <span class="st">"cox"</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb64"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-62-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>提取最优的 <span class="math inline">\(\lambda\)</span> 值</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb65"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.min</span></span>
<span><span class="co">#&gt; [1] 0.02107668</span></span>
<span><span class="va">cvfit</span><span class="op">$</span><span class="va">lambda.1se</span></span>
<span><span class="co">#&gt; [1] 0.05343706</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>提取模型系数：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb66"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">coef.min</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">cvfit</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="va">active.min</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="va">coef.min</span> <span class="op">!=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">index.min</span> <span class="op">=</span> <span class="va">coef.min</span><span class="op">[</span><span class="va">active.min</span><span class="op">]</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb67"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">index.min</span></span>
<span><span class="co">#&gt;  [1]  0.47296769 -0.16213158 -0.20518470  0.16374470 -0.17544445 -0.47500198</span></span>
<span><span class="co">#&gt;  [7]  0.32076305  0.08339592  0.43422644  0.10423130  0.01054257 -0.01125802</span></span>
<span><span class="co">#&gt; [13] -0.01541834</span></span>
<span><span class="va">coef.min</span></span>
<span><span class="co">#&gt; 30 x 1 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">#&gt;               1</span></span>
<span><span class="co">#&gt; V1   0.47296769</span></span>
<span><span class="co">#&gt; V2  -0.16213158</span></span>
<span><span class="co">#&gt; V3  -0.20518470</span></span>
<span><span class="co">#&gt; V4   0.16374470</span></span>
<span><span class="co">#&gt; V5  -0.17544445</span></span>
<span><span class="co">#&gt; V6  -0.47500198</span></span>
<span><span class="co">#&gt; V7   0.32076305</span></span>
<span><span class="co">#&gt; V8   0.08339592</span></span>
<span><span class="co">#&gt; V9   0.43422644</span></span>
<span><span class="co">#&gt; V10  0.10423130</span></span>
<span><span class="co">#&gt; V11  .         </span></span>
<span><span class="co">#&gt; V12  .         </span></span>
<span><span class="co">#&gt; V13  0.01054257</span></span>
<span><span class="co">#&gt; V14  .         </span></span>
<span><span class="co">#&gt; V15  .         </span></span>
<span><span class="co">#&gt; V16  .         </span></span>
<span><span class="co">#&gt; V17 -0.01125802</span></span>
<span><span class="co">#&gt; V18  .         </span></span>
<span><span class="co">#&gt; V19  .         </span></span>
<span><span class="co">#&gt; V20  .         </span></span>
<span><span class="co">#&gt; V21  .         </span></span>
<span><span class="co">#&gt; V22  .         </span></span>
<span><span class="co">#&gt; V23  .         </span></span>
<span><span class="co">#&gt; V24  .         </span></span>
<span><span class="co">#&gt; V25 -0.01541834</span></span>
<span><span class="co">#&gt; V26  .         </span></span>
<span><span class="co">#&gt; V27  .         </span></span>
<span><span class="co">#&gt; V28  .         </span></span>
<span><span class="co">#&gt; V29  .         </span></span>
<span><span class="co">#&gt; V30  .</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section></section><section id="稀疏矩阵" class="level2"><h2 class="anchored" data-anchor-id="稀疏矩阵">7 稀疏矩阵</h2>
<p>除了<code>cox</code>模型外，<code>glmnet</code>均支持稀疏矩阵作为输入，它的用法同常规矩阵的用法相同。</p>
<p>我们加载一个稀疏矩阵示例：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb68"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">SparseExample</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="va">SparseExample</span><span class="op">$</span><span class="va">x</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">SparseExample</span><span class="op">$</span><span class="va">y</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>加载的数据<code>x</code>为100*20的一个稀疏矩阵，<code>y</code>为响应变量(长度为100的向量）。</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb69"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] "dgCMatrix"</span></span>
<span><span class="co">#&gt; attr(,"package")</span></span>
<span><span class="co">#&gt; [1] "Matrix"</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>创建稀疏矩阵有两种方式，一种方式是采用<code>sparseMatrix</code>生成；还有一种方式是直接采用<code>Matrix</code>来构建。</p>
<p>当输入是稀疏矩阵时，调用<code>glmnet</code>的方式跟普通矩阵没有差别：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb70"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">fit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/glmnet.html">glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>交叉验证也一样：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb71"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">cvfit</span> <span class="op">=</span> <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">cvfit</span><span class="op">)</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<p><img src="glmnet1_files/figure-html/unnamed-chunk-69-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>稀疏矩阵除了可以用作<code>glmnet</code>的输入<code>x</code>，还可以用作<code>predict</code>函数的输入<code>newx</code>，我们来看看如下的例子：</p>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb72"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">i</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">5</span>, size <span class="op">=</span> <span class="fl">25</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">j</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">20</span>, size <span class="op">=</span> <span class="fl">25</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">25</span><span class="op">)</span></span>
<span><span class="va">nx</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/sparseMatrix.html">sparseMatrix</a></span><span class="op">(</span>i <span class="op">=</span> <span class="va">i</span>, j <span class="op">=</span> <span class="va">j</span>, x <span class="op">=</span> <span class="va">x</span>, dims <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">20</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">cvfit</span>, newx <span class="op">=</span> <span class="va">nx</span>, s <span class="op">=</span> <span class="st">"lambda.min"</span><span class="op">)</span></span>
<span><span class="co">#&gt;      lambda.min</span></span>
<span><span class="co">#&gt; [1,]  0.8286576</span></span>
<span><span class="co">#&gt; [2,] -0.1938951</span></span>
<span><span class="co">#&gt; [3,]  0.7690298</span></span>
<span><span class="co">#&gt; [4,] -0.4358310</span></span>
<span><span class="co">#&gt; [5,] -0.1450590</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details><summary>Show the code</summary><div class="sourceCode" id="cb73"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; R version 4.2.1 (2022-06-23)</span></span>
<span><span class="co">#&gt; Platform: aarch64-apple-darwin20 (64-bit)</span></span>
<span><span class="co">#&gt; Running under: macOS Monterey 12.5.1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Matrix products: default</span></span>
<span><span class="co">#&gt; BLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib</span></span>
<span><span class="co">#&gt; LAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; locale:</span></span>
<span><span class="co">#&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; attached base packages:</span></span>
<span><span class="co">#&gt; [1] parallel  stats     graphics  grDevices utils     datasets  methods  </span></span>
<span><span class="co">#&gt; [8] base     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; other attached packages:</span></span>
<span><span class="co">#&gt; [1] doParallel_1.0.17 doMC_1.3.8        iterators_1.0.14  foreach_1.5.2    </span></span>
<span><span class="co">#&gt; [5] glmnet_4.1-4      Matrix_1.4-1     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; loaded via a namespace (and not attached):</span></span>
<span><span class="co">#&gt;  [1] Rcpp_1.0.9        rstudioapi_0.14   knitr_1.40        magrittr_2.0.3   </span></span>
<span><span class="co">#&gt;  [5] splines_4.2.1     lattice_0.20-45   rlang_1.0.4       fastmap_1.1.0    </span></span>
<span><span class="co">#&gt;  [9] stringr_1.4.1     tools_4.2.1       grid_4.2.1        xfun_0.32        </span></span>
<span><span class="co">#&gt; [13] cli_3.3.0         htmltools_0.5.3   yaml_2.3.5        survival_3.4-0   </span></span>
<span><span class="co">#&gt; [17] digest_0.6.29     htmlwidgets_1.5.4 codetools_0.2-18  shape_1.4.6      </span></span>
<span><span class="co">#&gt; [21] evaluate_0.16     rmarkdown_2.16.1  stringi_1.7.8     compiler_4.2.1   </span></span>
<span><span class="co">#&gt; [25] jsonlite_1.8.0</span></span></code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>参考：https://web.stanford.edu/~hastie/glmnet/glmnet_beta.html</p>


<!-- -->

</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } 
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "已复制");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">源代码</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb74" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> glmnet包解读1</span></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> '2018-09-13'</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> r</span></span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup, include=FALSE}</span></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">message =</span> F,<span class="at">warning =</span> F,<span class="at">comment =</span> <span class="st">"#&gt;"</span>,<span class="at">collapse =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a><span class="fu">## 1 介绍</span></span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a><span class="in">`glmnet`</span> 包解决了一下问题（目标函数）</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a>\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} w_i l(y_i,\beta_0+\beta^T x_i) + \lambda\left<span class="co">[</span><span class="ot">(1-\alpha)||\beta||_2^2/2 + \alpha ||\beta||_1\right</span><span class="co">]</span>,</span>
<span id="cb74-18"><a href="#cb74-18" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-19"><a href="#cb74-19" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 1.1  glmnet包安装</span></span>
<span id="cb74-20"><a href="#cb74-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-21"><a href="#cb74-21" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, eval=FALSE}</span></span>
<span id="cb74-22"><a href="#cb74-22" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">"glmnet"</span>, <span class="at">repos =</span> <span class="st">"http://cran.us.r-project.org"</span>)</span>
<span id="cb74-23"><a href="#cb74-23" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-24"><a href="#cb74-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-25"><a href="#cb74-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## 2  快速开始</span></span>
<span id="cb74-26"><a href="#cb74-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-27"><a href="#cb74-27" aria-hidden="true" tabindex="-1"></a>这节介绍<span class="in">`glmnet`</span>包中的主要函数以及它们的一般用法，对常用函数的输入参数以及输出结果做简要的说明。 </span>
<span id="cb74-28"><a href="#cb74-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-29"><a href="#cb74-29" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2.1 加载glmnet包</span></span>
<span id="cb74-30"><a href="#cb74-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-33"><a href="#cb74-33" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-34"><a href="#cb74-34" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)<span class="co"># 加载glmnet包</span></span>
<span id="cb74-35"><a href="#cb74-35" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-36"><a href="#cb74-36" aria-hidden="true" tabindex="-1"></a>以线性回归为例，来说明<span class="in">`glmnet`</span>包的用法。</span>
<span id="cb74-37"><a href="#cb74-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-38"><a href="#cb74-38" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2.2 准备数据 </span></span>
<span id="cb74-39"><a href="#cb74-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-42"><a href="#cb74-42" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-43"><a href="#cb74-43" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(QuickStartExample)<span class="co">#x为100*20的矩阵 ,y为100 * 1的矩阵。</span></span>
<span id="cb74-44"><a href="#cb74-44" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> QuickStartExample<span class="sc">$</span>x</span>
<span id="cb74-45"><a href="#cb74-45" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> QuickStartExample<span class="sc">$</span>y</span>
<span id="cb74-46"><a href="#cb74-46" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-47"><a href="#cb74-47" aria-hidden="true" tabindex="-1"></a>该命令R数据存档中加载输入矩阵<span class="in">`x`</span>和响应向量<span class="in">`y`</span>。 <span class="in">`x`</span>为<span class="in">`100*20`</span>的矩阵 ,<span class="in">`y`</span>为<span class="in">`100 * 1`</span>的矩阵。</span>
<span id="cb74-48"><a href="#cb74-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-49"><a href="#cb74-49" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2.3 拟合模型</span></span>
<span id="cb74-50"><a href="#cb74-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-51"><a href="#cb74-51" aria-hidden="true" tabindex="-1"></a>数据有了，我们就可以调用包中与之同名的<span class="in">`glmnet`</span>函数来做线性回归了： </span>
<span id="cb74-52"><a href="#cb74-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-55"><a href="#cb74-55" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-56"><a href="#cb74-56" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y)</span>
<span id="cb74-57"><a href="#cb74-57" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-58"><a href="#cb74-58" aria-hidden="true" tabindex="-1"></a>这里生成的结果 “fit”是类的对象<span class="in">`glmnet`</span>，包含拟合模型的所有相关信息。不鼓励用户直接提取组件（像list那样提取）。推荐使用各种方法<span class="in">`plot`</span>，<span class="in">`print`</span>，<span class="in">`coef`</span>和<span class="in">`predict`</span>提取信息，这样能够使我们更优雅执行这些任务。 </span>
<span id="cb74-59"><a href="#cb74-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-60"><a href="#cb74-60" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2.4 模型对象的可视化</span></span>
<span id="cb74-61"><a href="#cb74-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-62"><a href="#cb74-62" aria-hidden="true" tabindex="-1"></a>采用<span class="in">`plot`</span>函数对拟合出的模型系数进行可视化： </span>
<span id="cb74-63"><a href="#cb74-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-66"><a href="#cb74-66" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-67"><a href="#cb74-67" aria-hidden="true" tabindex="-1"></a><span class="co"># label = T，可以显示变量的标签。</span></span>
<span id="cb74-68"><a href="#cb74-68" aria-hidden="true" tabindex="-1"></a><span class="co"># 参数xvar = c("norm", "lambda", "dev")</span></span>
<span id="cb74-69"><a href="#cb74-69" aria-hidden="true" tabindex="-1"></a><span class="co"># norm（默认）:  显示系数值和L1范数之间的变化关系</span></span>
<span id="cb74-70"><a href="#cb74-70" aria-hidden="true" tabindex="-1"></a><span class="co"># lambda： 显示系数值和对数lambda之间的变化关系</span></span>
<span id="cb74-71"><a href="#cb74-71" aria-hidden="true" tabindex="-1"></a><span class="co"># dev : 显示系数值如何随解释偏差百分比（dev）之间的变化关系</span></span>
<span id="cb74-72"><a href="#cb74-72" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit,<span class="at">label =</span> T)</span>
<span id="cb74-73"><a href="#cb74-73" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-74"><a href="#cb74-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-75"><a href="#cb74-75" aria-hidden="true" tabindex="-1"></a>上图中，每一条曲线代表一个变量的系数。Y轴是回归系数的值，X轴是L1范数，图中上方有另一条x轴，其数值表示模型的特征数，</span>
<span id="cb74-76"><a href="#cb74-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-77"><a href="#cb74-77" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2.5 模型对象信息的提取</span></span>
<span id="cb74-78"><a href="#cb74-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-79"><a href="#cb74-79" aria-hidden="true" tabindex="-1"></a>回到我们的拟合结果<span class="in">`fit`</span>。作为一个 R 对象，我们可以把它当作很多函数的输入。比如说，我们可以查看详细的拟合结果： </span>
<span id="cb74-80"><a href="#cb74-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-81"><a href="#cb74-81" aria-hidden="true" tabindex="-1"></a><span class="in">```{r height = 4}</span></span>
<span id="cb74-82"><a href="#cb74-82" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit)</span>
<span id="cb74-83"><a href="#cb74-83" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-84"><a href="#cb74-84" aria-hidden="true" tabindex="-1"></a>每一行代表了一个模型 ,它从左到右显示非零系数的个数（<span class="in">`Df`</span>），模型所解释的偏差的百分比（<span class="in">`%dev`</span>）和λ的值（<span class="in">`Lambda`</span>） （注意岭回归中列<span class="in">`Df`</span>的值是不会变的）</span>
<span id="cb74-85"><a href="#cb74-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-86"><a href="#cb74-86" aria-hidden="true" tabindex="-1"></a>通过<span class="in">`coef`</span>来提取模型的系数： </span>
<span id="cb74-87"><a href="#cb74-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-90"><a href="#cb74-90" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-91"><a href="#cb74-91" aria-hidden="true" tabindex="-1"></a><span class="co"># 参数s：指定lambda的值，可以是一个向量，则提取多个模型的系数，每一列对应一个模型的系数</span></span>
<span id="cb74-92"><a href="#cb74-92" aria-hidden="true" tabindex="-1"></a><span class="co"># 参数complete: 逻辑值,表示是否应该返回全系数向量.</span></span>
<span id="cb74-93"><a href="#cb74-93" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fit,<span class="at">s=</span><span class="fl">0.1</span>,<span class="at">exact=</span><span class="cn">FALSE</span>)</span>
<span id="cb74-94"><a href="#cb74-94" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-95"><a href="#cb74-95" aria-hidden="true" tabindex="-1"></a>用<span class="in">`coef`</span>来提取模型的系数,参数采用的是<span class="in">`s`</span> 而不是<span class="in">`lambda`</span>,---同样在<span class="in">`predict`</span>函数中一样的道理,eg:</span>
<span id="cb74-96"><a href="#cb74-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-97"><a href="#cb74-97" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2.6 预测</span></span>
<span id="cb74-98"><a href="#cb74-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-99"><a href="#cb74-99" aria-hidden="true" tabindex="-1"></a>预测采用<span class="in">`predict`</span>函数，参数<span class="in">`newx`</span>用来设置输入数据，<span class="in">`s`</span>用来设置$\lambda$的值：</span>
<span id="cb74-100"><a href="#cb74-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-103"><a href="#cb74-103" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-104"><a href="#cb74-104" aria-hidden="true" tabindex="-1"></a>nx <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">10</span><span class="sc">*</span><span class="dv">20</span>),<span class="dv">10</span>,<span class="dv">20</span>)</span>
<span id="cb74-105"><a href="#cb74-105" aria-hidden="true" tabindex="-1"></a><span class="co">#predict函数与coef函数相比多了一些参数的设置，参数newx设置待预测的输入数据集，以及tpye参数选项</span></span>
<span id="cb74-106"><a href="#cb74-106" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(fit,<span class="at">newx=</span>nx,<span class="at">s=</span><span class="fu">c</span>(<span class="fl">0.1</span>,<span class="fl">0.05</span>))</span>
<span id="cb74-107"><a href="#cb74-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-108"><a href="#cb74-108" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-109"><a href="#cb74-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-110"><a href="#cb74-110" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2.7  交叉验证</span></span>
<span id="cb74-111"><a href="#cb74-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-112"><a href="#cb74-112" aria-hidden="true" tabindex="-1"></a><span class="in">`glmnet`</span>提供了一系列的模型可供选择，而在大多数情况下我们需要从中挑选出一个最合适的来用就可以了。这时可以通过交叉验证的方法来筛选最优的λ值了，<span class="in">`cv.glmnet`</span>函数实现了这一功能。 也支持绘图和预测方法。 </span>
<span id="cb74-113"><a href="#cb74-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-114"><a href="#cb74-114" aria-hidden="true" tabindex="-1"></a>继续沿用之前的样本数据，调用<span class="in">`cv.glmnet`</span>函数： </span>
<span id="cb74-115"><a href="#cb74-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-118"><a href="#cb74-118" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-119"><a href="#cb74-119" aria-hidden="true" tabindex="-1"></a>cvfit <span class="ot">=</span> <span class="fu">cv.glmnet</span>(x, y)</span>
<span id="cb74-120"><a href="#cb74-120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-121"><a href="#cb74-121" aria-hidden="true" tabindex="-1"></a>可以看到，<span class="in">`cv.glmnet`</span>返回的结果是一个<span class="in">`cv.glmnet`</span>类的对象，该对象的类型和<span class="in">`glmnet`</span>函数返回的结果一样，它们本质上都是R中的list。 不鼓励直接提取信息，推荐使用各种函数提取.</span>
<span id="cb74-122"><a href="#cb74-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-123"><a href="#cb74-123" aria-hidden="true" tabindex="-1"></a>我们用可视化的图形来展示<span class="in">`cv.glmnet`</span>的结果： </span>
<span id="cb74-124"><a href="#cb74-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-127"><a href="#cb74-127" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-128"><a href="#cb74-128" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cvfit)</span>
<span id="cb74-129"><a href="#cb74-129" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-130"><a href="#cb74-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-131"><a href="#cb74-131" aria-hidden="true" tabindex="-1"></a>从图中可以看到MSE是如何随着lambda的不同取值而变化的。红色的散点为交叉验证的散点图，横轴为logλ，纵轴为均方误差，每个点的标准偏差上界和下界也画出来了。图的顶部字数表示非零系数的个数，第一条垂直线对应的是lambda.min的值，它是交叉验证提取出的最优值，第二条（从左往右看）是lambda.lse属性的值，它对应了距离lambda.min一个标准误差的值，并产生了一个更为正则化的模型 （<span class="in">`lambda.1se `</span>为离最小均方误差一倍标准差的λ值。 ）</span>
<span id="cb74-132"><a href="#cb74-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-133"><a href="#cb74-133" aria-hidden="true" tabindex="-1"></a>最优的λ 值可以直接采用如下命令来提取： </span>
<span id="cb74-134"><a href="#cb74-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-137"><a href="#cb74-137" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-138"><a href="#cb74-138" aria-hidden="true" tabindex="-1"></a>cvfit<span class="sc">$</span>lambda.min</span>
<span id="cb74-139"><a href="#cb74-139" aria-hidden="true" tabindex="-1"></a>cvfit<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb74-140"><a href="#cb74-140" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-141"><a href="#cb74-141" aria-hidden="true" tabindex="-1"></a>用<span class="in">`coef`</span>函数来提取回归模型的系数： </span>
<span id="cb74-142"><a href="#cb74-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-145"><a href="#cb74-145" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-146"><a href="#cb74-146" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cvfit, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb74-147"><a href="#cb74-147" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-148"><a href="#cb74-148" aria-hidden="true" tabindex="-1"></a>可以看到回归模型的系数是采用稀疏矩阵的形式来存储的。由于计算出的模型系数经常是稀疏的，这时采用稀疏矩阵的方式来存储和计算更有效率。如果你不习惯稀疏矩阵的输出形式，可以用<span class="in">`as.matrix()`</span>将其转化为传统的矩阵形式。 </span>
<span id="cb74-149"><a href="#cb74-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-150"><a href="#cb74-150" aria-hidden="true" tabindex="-1"></a>预测同<span class="in">`glmnet`</span>，直接采用<span class="in">`predict`</span>泛型函数即可： </span>
<span id="cb74-151"><a href="#cb74-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-154"><a href="#cb74-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-155"><a href="#cb74-155" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(cvfit, <span class="at">newx =</span> x[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,], <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb74-156"><a href="#cb74-156" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-157"><a href="#cb74-157" aria-hidden="true" tabindex="-1"></a>自此，<span class="in">`glmnet`</span>的入门介绍完了，你可以用来他做一些基本的回归模型了。</span>
<span id="cb74-158"><a href="#cb74-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-159"><a href="#cb74-159" aria-hidden="true" tabindex="-1"></a>接下来，我们对<span class="in">`glmnet`</span>包进行更为深入的介绍。</span>
<span id="cb74-160"><a href="#cb74-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-161"><a href="#cb74-161" aria-hidden="true" tabindex="-1"></a><span class="fu">## 3 线性回归</span></span>
<span id="cb74-162"><a href="#cb74-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-163"><a href="#cb74-163" aria-hidden="true" tabindex="-1"></a><span class="in">`glmnet`</span>中的线性回归主要包含两类。一定是高斯簇<span class="in">`gaussian`</span>，还有一类是多响应高斯簇<span class="in">`mgaussian`</span>。我们依次介绍： </span>
<span id="cb74-164"><a href="#cb74-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-165"><a href="#cb74-165" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.1 高斯簇</span></span>
<span id="cb74-166"><a href="#cb74-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-167"><a href="#cb74-167" aria-hidden="true" tabindex="-1"></a><span class="in">`gaussian `</span> 是<span class="in">`glmnet`</span>函数中的默认函数簇，它本质上是带正则项的多元线性回归的估计问题。</span>
<span id="cb74-168"><a href="#cb74-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-169"><a href="#cb74-169" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.1 优化目标</span></span>
<span id="cb74-170"><a href="#cb74-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-171"><a href="#cb74-171" aria-hidden="true" tabindex="-1"></a>优化的目标函数如下：（高斯族采用的是平方损失函数）</span>
<span id="cb74-172"><a href="#cb74-172" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-173"><a href="#cb74-173" aria-hidden="true" tabindex="-1"></a>\min_{(\beta_0, \beta) \in \mathbb{R}^{p+1}}\frac{1}{2N} \sum_{i=1}^N (y_i -\beta_0-x_i^T \beta)^2+\lambda \left<span class="co">[</span><span class="ot"> \dfrac{1}{2}(1-\alpha)||\beta||_2^2 + \alpha||\beta||_1\right</span><span class="co">]</span>,</span>
<span id="cb74-174"><a href="#cb74-174" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-175"><a href="#cb74-175" aria-hidden="true" tabindex="-1"></a>其中 $\lambda \geq 0$ 是模型复杂度参数 ;$0 \leq \alpha \leq 1$ ，当$\alpha = 0$ 时为岭回归，当$\alpha = 1$为lasso，在$0 &lt;\alpha &lt; 1$则为两者的折中.</span>
<span id="cb74-176"><a href="#cb74-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-177"><a href="#cb74-177" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.2 glmnet参数设置</span></span>
<span id="cb74-178"><a href="#cb74-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-179"><a href="#cb74-179" aria-hidden="true" tabindex="-1"></a><span class="in">`glmnet`</span>提供了很多参数可以供我们选择。下面介绍一些常用的参数设置：</span>
<span id="cb74-180"><a href="#cb74-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-181"><a href="#cb74-181" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`alpha`</span>之前介绍过，它是弹性网的参数，取值范围是<span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>, (且只能一个一个取，不能为向量)</span>
<span id="cb74-182"><a href="#cb74-182" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`weights`</span>配置观测的权重。默认每个观测的权重取值均为1。</span>
<span id="cb74-183"><a href="#cb74-183" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nlambda`</span>默认值是100。(系统自动挑选 100 个不同的 λ 值，拟合出 100 个系数不同的模型 ）</span>
<span id="cb74-184"><a href="#cb74-184" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`lambda`</span>一般是程序自动构建，也可以自己定义（可以是向量）。</span>
<span id="cb74-185"><a href="#cb74-185" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`standardize`</span>表示在拟合模型前，<span class="in">`x`</span>变量是否需要标准化。默认<span class="in">`standardize=TRUE`</span>。</span>
<span id="cb74-186"><a href="#cb74-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-187"><a href="#cb74-187" aria-hidden="true" tabindex="-1"></a>更多参数设置参考帮助文档<span class="in">`help(glmnet)`</span>。</span>
<span id="cb74-188"><a href="#cb74-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-189"><a href="#cb74-189" aria-hidden="true" tabindex="-1"></a>我们用下面的例子来看看这些参数的用法： 还是用原来的样本数据，不同的是取α = 0.2（接近岭回归的正则项），设置观测的权重以及 λ序列的数量： </span>
<span id="cb74-190"><a href="#cb74-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-193"><a href="#cb74-193" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-194"><a href="#cb74-194" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="fl">0.2</span>, <span class="at">weights =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,<span class="dv">50</span>),<span class="fu">rep</span>(<span class="dv">2</span>,<span class="dv">50</span>)), <span class="at">nlambda =</span> <span class="dv">20</span>)</span>
<span id="cb74-195"><a href="#cb74-195" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-196"><a href="#cb74-196" aria-hidden="true" tabindex="-1"></a>用<span class="in">`print`</span>函数打印结果： </span>
<span id="cb74-197"><a href="#cb74-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-200"><a href="#cb74-200" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-201"><a href="#cb74-201" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(fit)</span>
<span id="cb74-202"><a href="#cb74-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-203"><a href="#cb74-203" aria-hidden="true" tabindex="-1"></a>打印结果之前已做过说明，这里不再赘述。可以看到这里λ并没有达到预设的20。这是因为在偏差解释率达到0.999或者其变化小于10e-5时计算就会终止。而这些预设的计算终止条件可以通过<span class="in">`glmnet.control`</span>来设置，详见<span class="in">`help(glmnet.control)`</span>。 </span>
<span id="cb74-204"><a href="#cb74-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-205"><a href="#cb74-205" aria-hidden="true" tabindex="-1"></a>注意，可以设置<span class="in">`digits`</span>选项可用于指定打印输出中的有效数字 </span>
<span id="cb74-206"><a href="#cb74-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-207"><a href="#cb74-207" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.3 plot参数设置</span></span>
<span id="cb74-208"><a href="#cb74-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-209"><a href="#cb74-209" aria-hidden="true" tabindex="-1"></a>Y轴为模型的系数值。</span>
<span id="cb74-210"><a href="#cb74-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-211"><a href="#cb74-211" aria-hidden="true" tabindex="-1"></a><span class="in">`plot`</span>函数可以用<span class="in">`xvar`</span>来定义X轴的度量，有三种选项：</span>
<span id="cb74-212"><a href="#cb74-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-213"><a href="#cb74-213" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“norm” 表示系数的L1-范数(默认)，显示系数值和L1范数之间的变化关系</span>
<span id="cb74-214"><a href="#cb74-214" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“lambda” 表示对数lambda值，显示系数值和对数lambda之间的变化关系</span>
<span id="cb74-215"><a href="#cb74-215" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“dev” 表示偏差解释率，显示系数值如何随解释偏差百分比（dev）之间的变化关系</span>
<span id="cb74-216"><a href="#cb74-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-217"><a href="#cb74-217" aria-hidden="true" tabindex="-1"></a>在<span class="in">`plot`</span>函数中添加参数<span class="in">`label = TRUE`</span>可以显示变量的标签 </span>
<span id="cb74-218"><a href="#cb74-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-221"><a href="#cb74-221" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-222"><a href="#cb74-222" aria-hidden="true" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>),<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb74-223"><a href="#cb74-223" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"norm"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>,<span class="at">main=</span><span class="st">'nrom</span><span class="sc">\n</span><span class="st">'</span>)</span>
<span id="cb74-224"><a href="#cb74-224" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>,<span class="at">main=</span><span class="st">'lambda</span><span class="sc">\n</span><span class="st">'</span>)</span>
<span id="cb74-225"><a href="#cb74-225" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"dev"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>,<span class="at">main=</span><span class="st">'dev</span><span class="sc">\n</span><span class="st">'</span>)</span>
<span id="cb74-226"><a href="#cb74-226" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-227"><a href="#cb74-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-228"><a href="#cb74-228" aria-hidden="true" tabindex="-1"></a>每一条曲线代表一个变量的系数。Y轴是回归系数的值，X轴是L1范数(默认)，图中上方有另一条x轴，其数值表示模型的特征数，</span>
<span id="cb74-229"><a href="#cb74-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-230"><a href="#cb74-230" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.4 coef参数设置</span></span>
<span id="cb74-231"><a href="#cb74-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-232"><a href="#cb74-232" aria-hidden="true" tabindex="-1"></a>coef函数中最常用的两个参数为:</span>
<span id="cb74-233"><a href="#cb74-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-234"><a href="#cb74-234" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`s`</span> 指定λ值</span>
<span id="cb74-235"><a href="#cb74-235" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`complete`</span> 表示是否应该返回全系数向量.</span>
<span id="cb74-236"><a href="#cb74-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-239"><a href="#cb74-239" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-240"><a href="#cb74-240" aria-hidden="true" tabindex="-1"></a><span class="fu">any</span>(fit<span class="sc">$</span>lambda <span class="sc">==</span> <span class="fl">0.5</span>)</span>
<span id="cb74-241"><a href="#cb74-241" aria-hidden="true" tabindex="-1"></a>coef.exact <span class="ot">=</span> <span class="fu">coef</span>(fit, <span class="at">s =</span> <span class="fl">0.5</span>, <span class="at">complete =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-242"><a href="#cb74-242" aria-hidden="true" tabindex="-1"></a>coef.apprx <span class="ot">=</span> <span class="fu">coef</span>(fit, <span class="at">s =</span> <span class="fl">0.5</span>, <span class="at">complete =</span> <span class="cn">FALSE</span>)</span>
<span id="cb74-243"><a href="#cb74-243" aria-hidden="true" tabindex="-1"></a><span class="fu">cbind2</span>(coef.exact, coef.apprx)</span>
<span id="cb74-244"><a href="#cb74-244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-245"><a href="#cb74-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-246"><a href="#cb74-246" aria-hidden="true" tabindex="-1"></a>结论： 当<span class="in">`exact`</span>选取不同的参数时，提取的系数也存在一定程度的差异，但差距不大。没有特别要求的话，使用线性插值得到的结果已经够用了。 </span>
<span id="cb74-247"><a href="#cb74-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-248"><a href="#cb74-248" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.5 predict参数设置</span></span>
<span id="cb74-249"><a href="#cb74-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-250"><a href="#cb74-250" aria-hidden="true" tabindex="-1"></a><span class="in">`predict`</span>函数与<span class="in">`coef`</span>函数相比多了一些参数的设置：<span class="in">`newx`</span>是待预测的输入数据集。</span>
<span id="cb74-251"><a href="#cb74-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-252"><a href="#cb74-252" aria-hidden="true" tabindex="-1"></a><span class="in">`type`</span>有多个选项可供选择：</span>
<span id="cb74-253"><a href="#cb74-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-254"><a href="#cb74-254" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“link” 给出预测值</span>
<span id="cb74-255"><a href="#cb74-255" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“response” 对于gaussian簇，同“link”</span>
<span id="cb74-256"><a href="#cb74-256" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“coefficients” 计算给定<span class="in">`s`</span>下的系数矩阵</span>
<span id="cb74-257"><a href="#cb74-257" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“nonzero” list对象，存储每个<span class="in">`s`</span>下非0系数对应的下标</span>
<span id="cb74-258"><a href="#cb74-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-261"><a href="#cb74-261" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-262"><a href="#cb74-262" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(fit, <span class="at">newx =</span> x[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,], <span class="at">type =</span> <span class="st">"response"</span>, <span class="at">s =</span> <span class="fl">0.05</span>)</span>
<span id="cb74-263"><a href="#cb74-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-264"><a href="#cb74-264" aria-hidden="true" tabindex="-1"></a>上述命令表示在λ = 0.05时计算<span class="in">`x`</span>头5条观测的预测值。这里的<span class="in">`s`</span>可以是一个向量，当<span class="in">`s`</span>是一个多数值向量时，预测值则为一个矩阵。 </span>
<span id="cb74-265"><a href="#cb74-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-266"><a href="#cb74-266" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.6 交叉验证</span></span>
<span id="cb74-267"><a href="#cb74-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-268"><a href="#cb74-268" aria-hidden="true" tabindex="-1"></a><span class="fu">##### 3.1.6.1 普通计算</span></span>
<span id="cb74-269"><a href="#cb74-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-270"><a href="#cb74-270" aria-hidden="true" tabindex="-1"></a>这小节对<span class="in">`cv.glmnet`</span>函数的参数做简要说明：</span>
<span id="cb74-271"><a href="#cb74-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-272"><a href="#cb74-272" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`nfolds`</span> – 交叉验证数据集划分的份数</span>
<span id="cb74-273"><a href="#cb74-273" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`foldid`</span> – 自定义划分数据</span>
<span id="cb74-274"><a href="#cb74-274" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`type.measure`</span> – 定义交叉验证的损失函数，“deviance”和“mse”用的是平方损失，“mae”用的是平均绝对损失</span>
<span id="cb74-275"><a href="#cb74-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-276"><a href="#cb74-276" aria-hidden="true" tabindex="-1"></a>举一个列子：</span>
<span id="cb74-279"><a href="#cb74-279" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-280"><a href="#cb74-280" aria-hidden="true" tabindex="-1"></a><span class="co"># 做20重交叉验证，采用平均绝对损失</span></span>
<span id="cb74-281"><a href="#cb74-281" aria-hidden="true" tabindex="-1"></a>cvfit <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">type.measure =</span> <span class="st">"mse"</span>, <span class="at">nfolds =</span> <span class="dv">20</span>)</span>
<span id="cb74-282"><a href="#cb74-282" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-283"><a href="#cb74-283" aria-hidden="true" tabindex="-1"></a><span class="fu">##### 3.1.6.2  并行计算</span></span>
<span id="cb74-284"><a href="#cb74-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-285"><a href="#cb74-285" aria-hidden="true" tabindex="-1"></a><span class="in">`cv.glmnet `</span>也支持并行计算，不过要使其工作，用户必须加载<span class="in">`doMC`</span>并注册并行数量. 在这里给出一个简单的比较示例。 (不过很遗憾，win不能用)</span>
<span id="cb74-286"><a href="#cb74-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-289"><a href="#cb74-289" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-290"><a href="#cb74-290" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(doMC) <span class="co"># win不能用,可以下载下来，但是不能平行计算。</span></span>
<span id="cb74-291"><a href="#cb74-291" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("doMC", repos="http://R-Forge.R-project.org")</span></span>
<span id="cb74-292"><a href="#cb74-292" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoMC</span>(<span class="at">cores=</span><span class="dv">2</span>)</span>
<span id="cb74-293"><a href="#cb74-293" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="fl">1e4</span> <span class="sc">*</span> <span class="dv">200</span>), <span class="fl">1e4</span>, <span class="dv">200</span>)</span>
<span id="cb74-294"><a href="#cb74-294" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="fl">1e4</span>)</span>
<span id="cb74-295"><a href="#cb74-295" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(<span class="fu">cv.glmnet</span>(X, Y))</span>
<span id="cb74-296"><a href="#cb74-296" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>(<span class="fu">cv.glmnet</span>(X, Y, <span class="at">parallel =</span> <span class="cn">TRUE</span>))</span>
<span id="cb74-297"><a href="#cb74-297" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-298"><a href="#cb74-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-301"><a href="#cb74-301" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-302"><a href="#cb74-302" aria-hidden="true" tabindex="-1"></a><span class="co"># 看了一下帮助文档 可以改成doParallel 也不能用很奇怪</span></span>
<span id="cb74-303"><a href="#cb74-303" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb74-304"><a href="#cb74-304" aria-hidden="true" tabindex="-1"></a><span class="co"># Windows 可以使用的并行包，但在这里也不能进行并行计算，时间不变</span></span>
<span id="cb74-305"><a href="#cb74-305" aria-hidden="true" tabindex="-1"></a>cl<span class="ot">&lt;-</span><span class="fu">makeCluster</span>(<span class="dv">6</span>)</span>
<span id="cb74-306"><a href="#cb74-306" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cl)</span>
<span id="cb74-307"><a href="#cb74-307" aria-hidden="true" tabindex="-1"></a><span class="fu">system.time</span>({cvfit <span class="ot">=</span> <span class="fu">cv.glmnet</span>(x,y,<span class="at">parallel=</span><span class="cn">TRUE</span>)})</span>
<span id="cb74-308"><a href="#cb74-308" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cl)<span class="co"># 时间也没有明显提高</span></span>
<span id="cb74-309"><a href="#cb74-309" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-310"><a href="#cb74-310" aria-hidden="true" tabindex="-1"></a>如上所述，并行计算可以显着加速计算过程，尤其是对于大规模问题。 </span>
<span id="cb74-311"><a href="#cb74-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-312"><a href="#cb74-312" aria-hidden="true" tabindex="-1"></a><span class="fu">##### **3.1.6.3 提取最优参数**</span></span>
<span id="cb74-313"><a href="#cb74-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-314"><a href="#cb74-314" aria-hidden="true" tabindex="-1"></a>函数  <span class="in">`coef`</span> 和 <span class="in">`predict`</span> 处理<span class="in">` cv.glmnet`</span> 对象和处理  <span class="in">`glmnet`</span> 对象类似。不过处理<span class="in">` cv.glmnet`</span>对象时，在指定$s$参数是可以用两个特殊的字符:<span class="in">`lambda.1se`</span>和<span class="in">`lambda.min`</span></span>
<span id="cb74-315"><a href="#cb74-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-316"><a href="#cb74-316" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>"lambda.1se": 为离最小均方误差MSE一倍标准差的$\lambda$值。</span>
<span id="cb74-317"><a href="#cb74-317" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>"lambda.min": 达到最小MSE对应的$\lambda$值（即 交叉验证提取出的最优值）</span>
<span id="cb74-318"><a href="#cb74-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-321"><a href="#cb74-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-322"><a href="#cb74-322" aria-hidden="true" tabindex="-1"></a>cvfit<span class="sc">$</span>lambda.min</span>
<span id="cb74-323"><a href="#cb74-323" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cvfit, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb74-324"><a href="#cb74-324" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(cvfit, <span class="at">newx =</span> x[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,], <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb74-325"><a href="#cb74-325" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-326"><a href="#cb74-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-327"><a href="#cb74-327" aria-hidden="true" tabindex="-1"></a><span class="fu">##### 3.1.6.4  数据划分问题</span></span>
<span id="cb74-328"><a href="#cb74-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-329"><a href="#cb74-329" aria-hidden="true" tabindex="-1"></a>除了可以设置<span class="in">`nfolds`</span>来寻找合适的模型外，我们还可以通过<span class="in">`foldid`</span>设置相同的数据划分来选择最优的α值。 </span>
<span id="cb74-330"><a href="#cb74-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-333"><a href="#cb74-333" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-334"><a href="#cb74-334" aria-hidden="true" tabindex="-1"></a>foldid<span class="ot">=</span><span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,<span class="at">size=</span><span class="fu">length</span>(y),<span class="at">replace=</span><span class="cn">TRUE</span>)</span>
<span id="cb74-335"><a href="#cb74-335" aria-hidden="true" tabindex="-1"></a>cv1<span class="ot">=</span><span class="fu">cv.glmnet</span>(x,y,<span class="at">foldid=</span>foldid,<span class="at">alpha=</span><span class="dv">1</span>)</span>
<span id="cb74-336"><a href="#cb74-336" aria-hidden="true" tabindex="-1"></a>cv<span class="fl">.5</span><span class="ot">=</span><span class="fu">cv.glmnet</span>(x,y,<span class="at">foldid=</span>foldid,<span class="at">alpha=</span>.<span class="dv">5</span>)</span>
<span id="cb74-337"><a href="#cb74-337" aria-hidden="true" tabindex="-1"></a>cv0<span class="ot">=</span><span class="fu">cv.glmnet</span>(x,y,<span class="at">foldid=</span>foldid,<span class="at">alpha=</span><span class="dv">0</span>)</span>
<span id="cb74-338"><a href="#cb74-338" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-339"><a href="#cb74-339" aria-hidden="true" tabindex="-1"></a>进行对比</span>
<span id="cb74-342"><a href="#cb74-342" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-343"><a href="#cb74-343" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb74-344"><a href="#cb74-344" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv1);<span class="fu">plot</span>(cv<span class="fl">.5</span>);<span class="fu">plot</span>(cv0)</span>
<span id="cb74-345"><a href="#cb74-345" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">log</span>(cv1<span class="sc">$</span>lambda),cv1<span class="sc">$</span>cvm,<span class="at">pch=</span><span class="dv">19</span>,<span class="at">col=</span><span class="st">"red"</span>,<span class="at">xlab=</span><span class="st">"log(Lambda)"</span>,<span class="at">ylab=</span>cv1<span class="sc">$</span>name)</span>
<span id="cb74-346"><a href="#cb74-346" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">log</span>(cv<span class="fl">.5</span><span class="sc">$</span>lambda),cv<span class="fl">.5</span><span class="sc">$</span>cvm,<span class="at">pch=</span><span class="dv">19</span>,<span class="at">col=</span><span class="st">"grey"</span>)</span>
<span id="cb74-347"><a href="#cb74-347" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(<span class="fu">log</span>(cv0<span class="sc">$</span>lambda),cv0<span class="sc">$</span>cvm,<span class="at">pch=</span><span class="dv">19</span>,<span class="at">col=</span><span class="st">"blue"</span>)</span>
<span id="cb74-348"><a href="#cb74-348" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">"topleft"</span>,<span class="at">legend=</span><span class="fu">c</span>(<span class="st">"alpha= 1"</span>,<span class="st">"alpha= .5"</span>,<span class="st">"alpha 0"</span>),<span class="at">pch=</span><span class="dv">19</span>,<span class="at">col=</span><span class="fu">c</span>(<span class="st">"red"</span>,<span class="st">"grey"</span>,<span class="st">"blue"</span>))</span>
<span id="cb74-349"><a href="#cb74-349" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-350"><a href="#cb74-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-351"><a href="#cb74-351" aria-hidden="true" tabindex="-1"></a>我们可以看到这里选择lasso(<span class="in">`alpha=1`</span>)时，模型的均方误差最小。 </span>
<span id="cb74-352"><a href="#cb74-352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-353"><a href="#cb74-353" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.7 系数上限和下限</span></span>
<span id="cb74-354"><a href="#cb74-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-355"><a href="#cb74-355" aria-hidden="true" tabindex="-1"></a>这些是最近添加的功能，可以增强模型的范围。假设我们想要拟合我们的模型，但是要将系数限制为大于-0.7且小于0.5。这可以通过<span class="in">`upper.limits`</span>和<span class="in">`lower.limits`</span>参数轻松实现： </span>
<span id="cb74-356"><a href="#cb74-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-359"><a href="#cb74-359" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-360"><a href="#cb74-360" aria-hidden="true" tabindex="-1"></a>tfit<span class="ot">=</span><span class="fu">glmnet</span>(x,y,<span class="at">lower=</span><span class="sc">-</span>.<span class="dv">7</span>,<span class="at">upper=</span>.<span class="dv">5</span>)</span>
<span id="cb74-361"><a href="#cb74-361" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tfit)</span>
<span id="cb74-362"><a href="#cb74-362" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-363"><a href="#cb74-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-364"><a href="#cb74-364" aria-hidden="true" tabindex="-1"></a>这些是相当随意的限制; 通常我们希望系数为正，所以我们只能设置<span class="in">`lower.limit`</span>为0 </span>
<span id="cb74-365"><a href="#cb74-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-366"><a href="#cb74-366" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 注意,上下限的取值范围 ：upper.limits的值不能小于0，lower.limits的值不能大于0 ,另外，如果想对每一个变量的系数对不同的限定，需要将这里的单点值即标量改为向量的形式就可以了。</span></span>
<span id="cb74-367"><a href="#cb74-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-368"><a href="#cb74-368" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.8  惩罚因子 </span></span>
<span id="cb74-369"><a href="#cb74-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-370"><a href="#cb74-370" aria-hidden="true" tabindex="-1"></a>这个参数可以给每一个系数提供一个单独的惩罚因子。该惩罚因子默认是1，它也支持自定义。如果将惩罚因子全部设置成为0的话，相当于就没有惩罚项了。 </span>
<span id="cb74-371"><a href="#cb74-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-372"><a href="#cb74-372" aria-hidden="true" tabindex="-1"></a>看看以下公式就一目了然了： </span>
<span id="cb74-373"><a href="#cb74-373" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-374"><a href="#cb74-374" aria-hidden="true" tabindex="-1"></a>\lambda \sum_{j=1}^p \boldsymbol{v_j} P_\alpha(\beta_j) = \lambda \sum_{j=1}^p \boldsymbol{v_j} \left<span class="co">[</span><span class="ot"> (1-\alpha)\frac{1}{2} \beta_j^2 + \alpha |\beta_j| \right</span><span class="co">]</span>.</span>
<span id="cb74-375"><a href="#cb74-375" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-376"><a href="#cb74-376" aria-hidden="true" tabindex="-1"></a>这个参数设置选项很有用，假如我们知道了一些先验信息，知道了其中一些变量很重要，需要在建模正则化的同时一直保留这些变量，那么可以把这些变量对应系数的惩罚因子设置为0。 </span>
<span id="cb74-377"><a href="#cb74-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-378"><a href="#cb74-378" aria-hidden="true" tabindex="-1"></a>同样用之前的数据，我们把第5、10、15个变量对应的惩罚因子设置为0： </span>
<span id="cb74-379"><a href="#cb74-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-382"><a href="#cb74-382" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-383"><a href="#cb74-383" aria-hidden="true" tabindex="-1"></a>p.fac <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="dv">20</span>)</span>
<span id="cb74-384"><a href="#cb74-384" aria-hidden="true" tabindex="-1"></a>p.fac[<span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>)] <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb74-385"><a href="#cb74-385" aria-hidden="true" tabindex="-1"></a>pfit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y, <span class="at">penalty.factor =</span> p.fac)</span>
<span id="cb74-386"><a href="#cb74-386" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pfit, <span class="at">label =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-387"><a href="#cb74-387" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-388"><a href="#cb74-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-389"><a href="#cb74-389" aria-hidden="true" tabindex="-1"></a>从上图中可以看到，变量5、10、15对应的系数一直都在模型中。 </span>
<span id="cb74-390"><a href="#cb74-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-391"><a href="#cb74-391" aria-hidden="true" tabindex="-1"></a>还有一些其它的有用的参数，比如，<span class="in">`exclude`</span>参数可以用来限制指定的变量入选模型；<span class="in">`intercept`</span>参数可以用来设定模型是否含有截距项等等。更多设置参考帮助文档<span class="in">`help(cv.glmnet)`</span>. </span>
<span id="cb74-392"><a href="#cb74-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-393"><a href="#cb74-393" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.1.9  自定义图</span></span>
<span id="cb74-394"><a href="#cb74-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-395"><a href="#cb74-395" aria-hidden="true" tabindex="-1"></a>有时，特别是当变量数量很少时，我们希望将变量标签添加到绘图中，而不是用变量的所在数据集中的下标。 如下：简单生成一组数据，拟合一个glmnet模型 ，并画出图</span>
<span id="cb74-396"><a href="#cb74-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-399"><a href="#cb74-399" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-400"><a href="#cb74-400" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb74-401"><a href="#cb74-401" aria-hidden="true" tabindex="-1"></a>x<span class="ot">=</span><span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">1000</span>),<span class="dv">100</span>,<span class="dv">10</span>)</span>
<span id="cb74-402"><a href="#cb74-402" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb74-403"><a href="#cb74-403" aria-hidden="true" tabindex="-1"></a>vn<span class="ot">=</span><span class="fu">paste</span>(<span class="st">"var"</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>) </span>
<span id="cb74-404"><a href="#cb74-404" aria-hidden="true" tabindex="-1"></a>fit<span class="ot">=</span><span class="fu">glmnet</span>(x,y)</span>
<span id="cb74-405"><a href="#cb74-405" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit)</span>
<span id="cb74-406"><a href="#cb74-406" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-407"><a href="#cb74-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-408"><a href="#cb74-408" aria-hidden="true" tabindex="-1"></a>然而我们想要的是用变量名称标记曲线 ，如下：</span>
<span id="cb74-409"><a href="#cb74-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-412"><a href="#cb74-412" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-413"><a href="#cb74-413" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.5</span>,<span class="fl">4.5</span>,<span class="dv">1</span>,<span class="dv">4</span>))</span>
<span id="cb74-414"><a href="#cb74-414" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit)</span>
<span id="cb74-415"><a href="#cb74-415" aria-hidden="true" tabindex="-1"></a>vnat<span class="ot">=</span><span class="fu">coef</span>(fit)</span>
<span id="cb74-416"><a href="#cb74-416" aria-hidden="true" tabindex="-1"></a>vnat<span class="ot">=</span>vnat[<span class="sc">-</span><span class="dv">1</span>,<span class="fu">ncol</span>(vnat)] <span class="co"># remove the intercept, and get the coefficients at the end of the path</span></span>
<span id="cb74-417"><a href="#cb74-417" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">4</span>, <span class="at">at=</span>vnat,<span class="at">line=</span><span class="sc">-</span>.<span class="dv">5</span>,<span class="at">label=</span>vn,<span class="at">las=</span><span class="dv">1</span>,<span class="at">tick=</span><span class="cn">FALSE</span>, <span class="at">cex.axis=</span><span class="fl">0.5</span>)</span>
<span id="cb74-418"><a href="#cb74-418" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-419"><a href="#cb74-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-420"><a href="#cb74-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-421"><a href="#cb74-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-422"><a href="#cb74-422" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3.2  多响应高斯簇</span></span>
<span id="cb74-423"><a href="#cb74-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-424"><a href="#cb74-424" aria-hidden="true" tabindex="-1"></a>多响应高斯簇模型的估计需要在<span class="in">`glmnet`</span>函数中设置<span class="in">`family = "mgaussian"`</span>。与以上单变量响应模型类似，它只是响应变量增多了，我们通常称之为“多任务学习”问题。虽然响应变量增多了，但是建模时所选择的自变量是完全一样的，只是待估系数不同而已。</span>
<span id="cb74-425"><a href="#cb74-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-426"><a href="#cb74-426" aria-hidden="true" tabindex="-1"></a>很显然，模型的因变量不再是一个向量形式，而是一个二维矩阵，这时估计出的系数也会是一个矩阵，先看看多响应高斯簇模型解决的问题：</span>
<span id="cb74-427"><a href="#cb74-427" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-428"><a href="#cb74-428" aria-hidden="true" tabindex="-1"></a>\min_{(\beta_0, \beta) \in \mathbb{R}^{(p+1)\times K}}\frac{1}{2N} \sum_{i=1}^N ||y_i -\beta_0-\beta^T x_i||^2_F+\lambda \left<span class="co">[</span><span class="ot"> (1-\alpha)||\beta||_F^2/2 + \alpha\sum_{j=1}^p||\beta_j||_2\right</span><span class="co">]</span>.</span>
<span id="cb74-429"><a href="#cb74-429" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-430"><a href="#cb74-430" aria-hidden="true" tabindex="-1"></a>这里的βj是$p\times K$维的系数矩阵$\beta$的第j行。</span>
<span id="cb74-431"><a href="#cb74-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-432"><a href="#cb74-432" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.2.1 载入演示数据</span></span>
<span id="cb74-433"><a href="#cb74-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-436"><a href="#cb74-436" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-437"><a href="#cb74-437" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(MultiGaussianExample)<span class="co"># 产生x,y两个矩阵，x的维度100*20 ,y的维度100 * 4。</span></span>
<span id="cb74-438"><a href="#cb74-438" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> MultiGaussianExample<span class="sc">$</span>x</span>
<span id="cb74-439"><a href="#cb74-439" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> MultiGaussianExample<span class="sc">$</span>y</span>
<span id="cb74-440"><a href="#cb74-440" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-441"><a href="#cb74-441" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.2.2 拟合模型</span></span>
<span id="cb74-442"><a href="#cb74-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-445"><a href="#cb74-445" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-446"><a href="#cb74-446" aria-hidden="true" tabindex="-1"></a>mfit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"mgaussian"</span>)</span>
<span id="cb74-447"><a href="#cb74-447" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-448"><a href="#cb74-448" aria-hidden="true" tabindex="-1"></a>多响应高斯模型与单响应高斯模型的大部分参数设置相同，如<span class="in">`alpha`</span>,<span class="in">`weights`</span>,<span class="in">`nlambda`</span>,<span class="in">`standardize`</span>。**但是`mgaussian`簇有一个额外的参数`standardize.response`，它可以用来给响应变量做标准化，默认为`FALSE`**。 </span>
<span id="cb74-449"><a href="#cb74-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-450"><a href="#cb74-450" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.2.3 查看拟合效果</span></span>
<span id="cb74-451"><a href="#cb74-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-452"><a href="#cb74-452" aria-hidden="true" tabindex="-1"></a>用<span class="in">`plot`</span>函数查看系数的变化： </span>
<span id="cb74-453"><a href="#cb74-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-456"><a href="#cb74-456" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-457"><a href="#cb74-457" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mfit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>, <span class="at">type.coef =</span> <span class="st">"2norm"</span>)</span>
<span id="cb74-458"><a href="#cb74-458" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mfit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>, <span class="at">type.coef =</span> <span class="st">"coef"</span>)</span>
<span id="cb74-459"><a href="#cb74-459" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-460"><a href="#cb74-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-461"><a href="#cb74-461" aria-hidden="true" tabindex="-1"></a>其中<span class="in">`xvar`</span>并且<span class="in">`label`</span>两个参数的设置与单响应的高斯模型一样 。这里的<span class="in">`type.coef = "2norm"`</span>表示每个变量的系数以二范数的形式展现。默认设置为<span class="in">`type.coef = "coef"`</span>，这时每个响应变量会展示一张系数变化的图。 </span>
<span id="cb74-462"><a href="#cb74-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-463"><a href="#cb74-463" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.2.4 预测</span></span>
<span id="cb74-464"><a href="#cb74-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-465"><a href="#cb74-465" aria-hidden="true" tabindex="-1"></a>可以通过<span class="in">`coef`</span>函数提取系数 ，<span class="in">`predict`</span>函数进行预测。用法和但响应的高斯模型一样，下面看看<span class="in">`predict`</span>的用法：</span>
<span id="cb74-466"><a href="#cb74-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-469"><a href="#cb74-469" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-470"><a href="#cb74-470" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(mfit, <span class="at">newx =</span> x[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,], <span class="at">s =</span> <span class="fu">c</span>(<span class="fl">0.1</span>, <span class="fl">0.01</span>))</span>
<span id="cb74-471"><a href="#cb74-471" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-472"><a href="#cb74-472" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3.2.5 交叉验证</span></span>
<span id="cb74-473"><a href="#cb74-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-474"><a href="#cb74-474" aria-hidden="true" tabindex="-1"></a>同样的交叉验证用<span class="in">`cv.glmnet`</span>函数： </span>
<span id="cb74-475"><a href="#cb74-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-478"><a href="#cb74-478" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-479"><a href="#cb74-479" aria-hidden="true" tabindex="-1"></a>cvmfit <span class="ot">=</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"mgaussian"</span>)</span>
<span id="cb74-480"><a href="#cb74-480" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-481"><a href="#cb74-481" aria-hidden="true" tabindex="-1"></a>画出交叉验证的结果： </span>
<span id="cb74-482"><a href="#cb74-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-485"><a href="#cb74-485" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-486"><a href="#cb74-486" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cvmfit)</span>
<span id="cb74-487"><a href="#cb74-487" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-488"><a href="#cb74-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-489"><a href="#cb74-489" aria-hidden="true" tabindex="-1"></a>想要查看最优的$\lambda$,,采用如下命令:</span>
<span id="cb74-490"><a href="#cb74-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-493"><a href="#cb74-493" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-494"><a href="#cb74-494" aria-hidden="true" tabindex="-1"></a>cvmfit<span class="sc">$</span>lambda.min</span>
<span id="cb74-495"><a href="#cb74-495" aria-hidden="true" tabindex="-1"></a>cvmfit<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb74-496"><a href="#cb74-496" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-497"><a href="#cb74-497" aria-hidden="true" tabindex="-1"></a>和以前一样，第一个是达到最小均方误差的值，第二个是最正则化模型，其均方误差在最小值的一个标准误差范围内 </span>
<span id="cb74-498"><a href="#cb74-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-499"><a href="#cb74-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-500"><a href="#cb74-500" aria-hidden="true" tabindex="-1"></a><span class="fu">## 4 逻辑回归</span></span>
<span id="cb74-501"><a href="#cb74-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-502"><a href="#cb74-502" aria-hidden="true" tabindex="-1"></a>逻辑回归是分类问题中最常用的模型之一。如果是一个二分类问题，一般假定响应变量服从二项分布，如果是多分类问题，则假定服从多项式分布。 </span>
<span id="cb74-503"><a href="#cb74-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-504"><a href="#cb74-504" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.1 二项分布逻辑回归</span></span>
<span id="cb74-505"><a href="#cb74-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-506"><a href="#cb74-506" aria-hidden="true" tabindex="-1"></a>假定响应变量的取值为 $\mathcal{G}=<span class="sc">\{</span>1,2<span class="sc">\}</span>$.定义 $y_i = I(g_i=1)$.则有</span>
<span id="cb74-507"><a href="#cb74-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-508"><a href="#cb74-508" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-509"><a href="#cb74-509" aria-hidden="true" tabindex="-1"></a>\mbox{Pr}(G=2|X=x)+\frac{e^{\beta_0+\beta^Tx}}{1+e^{\beta_0+\beta^Tx}}</span>
<span id="cb74-510"><a href="#cb74-510" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-511"><a href="#cb74-511" aria-hidden="true" tabindex="-1"></a>我们可以两边取对数，改写为如下形式（称为对数似然函数）：</span>
<span id="cb74-512"><a href="#cb74-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-513"><a href="#cb74-513" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-514"><a href="#cb74-514" aria-hidden="true" tabindex="-1"></a>\log\frac{\mbox{Pr}(G=2|X=x)}{\mbox{Pr}(G=1|X=x)}=\beta_0+\beta^Tx</span>
<span id="cb74-515"><a href="#cb74-515" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-516"><a href="#cb74-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-517"><a href="#cb74-517" aria-hidden="true" tabindex="-1"></a>这个带惩罚逻辑回归的目标函数的对数似然如下： </span>
<span id="cb74-518"><a href="#cb74-518" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-519"><a href="#cb74-519" aria-hidden="true" tabindex="-1"></a>\min_{(\beta_0, \beta) \in \mathbb{R}^{p+1}} -\left<span class="co">[</span><span class="ot">\frac{1}{N} \sum_{i=1}^N y_i \cdot (\beta_0 + x_i^T \beta) - \log (1+e^{(\beta_0+x_i^T \beta)})\right</span><span class="co">]</span> + \lambda \big<span class="co">[</span><span class="ot"> (1-\alpha)||\beta||_2^2/2 + \alpha||\beta||_1\big</span><span class="co">]</span>.</span>
<span id="cb74-520"><a href="#cb74-520" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-521"><a href="#cb74-521" aria-hidden="true" tabindex="-1"></a>当  $p &gt; N$ 时，逻辑回归常常伴随着退化的困扰 ，当$N$接近$p$时，甚至在表现出野蛮的行为 。弹性网惩罚缓解了这些问题。</span>
<span id="cb74-522"><a href="#cb74-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-523"><a href="#cb74-523" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.1.1 载入示例数据集</span></span>
<span id="cb74-524"><a href="#cb74-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-527"><a href="#cb74-527" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-528"><a href="#cb74-528" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BinomialExample)<span class="co"># 产生名为x维度为100*30的矩阵 ,名为y长度为100的int向量（0、1向量）</span></span>
<span id="cb74-529"><a href="#cb74-529" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> BinomialExample<span class="sc">$</span>x</span>
<span id="cb74-530"><a href="#cb74-530" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> BinomialExample<span class="sc">$</span>y</span>
<span id="cb74-531"><a href="#cb74-531" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-532"><a href="#cb74-532" aria-hidden="true" tabindex="-1"></a>这里的输入x与其他分布簇相同，对于二项Logistic回归，响应变量y应该是具有两个级别的因子，或者是计数或比例的两列矩阵  </span>
<span id="cb74-533"><a href="#cb74-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-534"><a href="#cb74-534" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.1.2 拟合模型</span></span>
<span id="cb74-535"><a href="#cb74-535" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-536"><a href="#cb74-536" aria-hidden="true" tabindex="-1"></a><span class="in">`glmnet`</span>二项式回归的其他可选参数与高斯族的几乎相同.仅需要把函数簇改为<span class="in">`family = "binomial"`</span>即可： </span>
<span id="cb74-537"><a href="#cb74-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-540"><a href="#cb74-540" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-541"><a href="#cb74-541" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"binomial"</span>)</span>
<span id="cb74-542"><a href="#cb74-542" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-543"><a href="#cb74-543" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.1.3 查看拟合效果</span></span>
<span id="cb74-544"><a href="#cb74-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-545"><a href="#cb74-545" aria-hidden="true" tabindex="-1"></a>同样， 我们可以用<span class="in">`print`</span>和<span class="in">`plot`</span>函数去查看对象 , 用<span class="in">`coef`</span>提取特定λ的系数，用<span class="in">`predict`</span>可以做出预测 .</span>
<span id="cb74-546"><a href="#cb74-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-549"><a href="#cb74-549" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-550"><a href="#cb74-550" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"dev"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-551"><a href="#cb74-551" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-552"><a href="#cb74-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-553"><a href="#cb74-553" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.1.4 预测</span></span>
<span id="cb74-554"><a href="#cb74-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-555"><a href="#cb74-555" aria-hidden="true" tabindex="-1"></a>逻辑回归的预测同高斯簇函数的用法有点不同，主要体现在参数<span class="in">`type`</span>的设置上，详细概括如下：</span>
<span id="cb74-556"><a href="#cb74-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-557"><a href="#cb74-557" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“link” 线性拟合值</span>
<span id="cb74-558"><a href="#cb74-558" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“response” 拟合的概率值</span>
<span id="cb74-559"><a href="#cb74-559" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“class” 给出计算出的最大概率对应的类的标签</span>
<span id="cb74-560"><a href="#cb74-560" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“coefficients” 计算给定<span class="in">`s`</span>下的系数的估计值</span>
<span id="cb74-561"><a href="#cb74-561" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“nonzero” 返回一个list对象，该list包含每一个<span class="in">`s`</span>对应非零系数的索引</span>
<span id="cb74-562"><a href="#cb74-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-563"><a href="#cb74-563" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 对于“二项式”模型，预测结果仅仅是针对响应变量的第二个水平(“link”, “response”, “coefficients”, “nonzero”)  (可以用</span><span class="in">`level`</span><span class="at">函数查看第二级别的类)</span></span>
<span id="cb74-564"><a href="#cb74-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-567"><a href="#cb74-567" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-568"><a href="#cb74-568" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(fit, <span class="at">newx =</span> x[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,], <span class="at">type =</span> <span class="st">"class"</span>, <span class="at">s =</span> <span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.01</span>))</span>
<span id="cb74-569"><a href="#cb74-569" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-570"><a href="#cb74-570" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.1.5 交叉验证</span></span>
<span id="cb74-571"><a href="#cb74-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-572"><a href="#cb74-572" aria-hidden="true" tabindex="-1"></a>逻辑回归的<span class="in">`cv.glmnet`</span>的用法同高斯簇函数，<span class="in">`nfolds`</span>, <span class="in">`weights`</span>, <span class="in">`lambda`</span>,<span class="in">`parallel`</span>的设置一样，区别主要在<span class="in">`type.measure`</span>：</span>
<span id="cb74-573"><a href="#cb74-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-574"><a href="#cb74-574" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>“mse” 用平方损失</span>
<span id="cb74-575"><a href="#cb74-575" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>“deviance” 用真实偏差</span>
<span id="cb74-576"><a href="#cb74-576" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>“mae” 用平均绝对误差</span>
<span id="cb74-577"><a href="#cb74-577" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>“class” 用误分类率</span>
<span id="cb74-578"><a href="#cb74-578" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>“auc” ROC曲线的下面积(这个选项仅针对两分类逻辑回归)。是现在最流行的综合考量模型性能的一种参数 </span>
<span id="cb74-579"><a href="#cb74-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-580"><a href="#cb74-580" aria-hidden="true" tabindex="-1"></a>例如，用误分类率误差为标准做十折交叉验证，代码如下： </span>
<span id="cb74-581"><a href="#cb74-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-584"><a href="#cb74-584" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-585"><a href="#cb74-585" aria-hidden="true" tabindex="-1"></a>cvfit <span class="ot">=</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"binomial"</span>, <span class="at">type.measure =</span> <span class="st">"class"</span>)</span>
<span id="cb74-586"><a href="#cb74-586" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-587"><a href="#cb74-587" aria-hidden="true" tabindex="-1"></a>用<span class="in">`plot`</span>查看<span class="in">`cv.glmnet`</span>生成的结果： . </span>
<span id="cb74-588"><a href="#cb74-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-591"><a href="#cb74-591" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-592"><a href="#cb74-592" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cvfit)</span>
<span id="cb74-593"><a href="#cb74-593" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-596"><a href="#cb74-596" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-597"><a href="#cb74-597" aria-hidden="true" tabindex="-1"></a>cvfit<span class="sc">$</span>lambda.min <span class="co">#查看最优的λ值</span></span>
<span id="cb74-598"><a href="#cb74-598" aria-hidden="true" tabindex="-1"></a>cvfit<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb74-599"><a href="#cb74-599" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-600"><a href="#cb74-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-601"><a href="#cb74-601" aria-hidden="true" tabindex="-1"></a><span class="in">`coef`</span>和<span class="in">`predict`</span>与高斯簇类似： </span>
<span id="cb74-602"><a href="#cb74-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-605"><a href="#cb74-605" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-606"><a href="#cb74-606" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cvfit, <span class="at">s =</span> <span class="st">"lambda.min"</span>) <span class="co"># 如前所述，此处返回的结果仅适用于响应变量的第二个水平。</span></span>
<span id="cb74-607"><a href="#cb74-607" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-608"><a href="#cb74-608" aria-hidden="true" tabindex="-1"></a>As mentioned previously, the results returned here are only for the second level of the factor response.</span>
<span id="cb74-609"><a href="#cb74-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-612"><a href="#cb74-612" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-613"><a href="#cb74-613" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(cvfit, <span class="at">newx =</span> x[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,], <span class="at">s =</span> <span class="st">"lambda.min"</span>, <span class="at">type =</span> <span class="st">"class"</span>)</span>
<span id="cb74-614"><a href="#cb74-614" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-615"><a href="#cb74-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-616"><a href="#cb74-616" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4.2 多分类逻辑回归</span></span>
<span id="cb74-617"><a href="#cb74-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-618"><a href="#cb74-618" aria-hidden="true" tabindex="-1"></a>多分类逻辑回归假定响应变量服从多项式分布, 假定响应变量有K个水平 ${\cal G}=<span class="sc">\{</span>1,2,\ldots,K<span class="sc">\}</span>$。则有</span>
<span id="cb74-619"><a href="#cb74-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-620"><a href="#cb74-620" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-621"><a href="#cb74-621" aria-hidden="true" tabindex="-1"></a>\mbox{Pr}(G=k|X=x)=\frac{e^{\beta_{0k}+\beta_k^Tx}}{\sum_{\ell=1}^Ke^{\beta_{0\ell}+\beta_\ell^Tx}}.</span>
<span id="cb74-622"><a href="#cb74-622" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-623"><a href="#cb74-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-624"><a href="#cb74-624" aria-hidden="true" tabindex="-1"></a>${Y}$ 应该是 $N \times K$ 的响应矩阵（把离散变量进行one-hot编码即可）  ,那么带弹性网惩罚项的非负对数似然函数如下： </span>
<span id="cb74-625"><a href="#cb74-625" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-626"><a href="#cb74-626" aria-hidden="true" tabindex="-1"></a>\ell(<span class="sc">\{</span>\beta_{0k},\beta_{k}<span class="sc">\}</span>_1^K) = -\left[\frac{1}{N} \sum_{i=1}^N \Big(\sum_{k=1}^Ky_{il} (\beta_{0k} + x_i^T \beta_k)- \log \big(\sum_{k=1}^K e^{\beta_{0k}+x_i^T \beta_k}\big)\Big)\right] +\lambda \left[ (1-\alpha)||\beta||_F^2/2 + \alpha\sum_{j=1}^p||\beta_j||_q\right].</span>
<span id="cb74-627"><a href="#cb74-627" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-628"><a href="#cb74-628" aria-hidden="true" tabindex="-1"></a>这里β是一个$p\times K$维的系数矩阵 $\beta_k$ 是其中的第$k$列,表示第$k$个模型对应模型的系数  , $\beta_j$ 第$j$行，表示第$j$个变量前面的系数。 </span>
<span id="cb74-629"><a href="#cb74-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-630"><a href="#cb74-630" aria-hidden="true" tabindex="-1"></a>后面的惩罚项  $||\beta_j||_q$, 有两种情形 $q\in <span class="sc">\{</span>1,2<span class="sc">\}</span>$.当q=1时，它是一个lasso惩罚项；当q=2时，它是一个grouped-lasso惩罚项。 </span>
<span id="cb74-631"><a href="#cb74-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-632"><a href="#cb74-632" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.2.1 载入示例数据集</span></span>
<span id="cb74-633"><a href="#cb74-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-634"><a href="#cb74-634" aria-hidden="true" tabindex="-1"></a>首先载入数据集：</span>
<span id="cb74-635"><a href="#cb74-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-638"><a href="#cb74-638" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-639"><a href="#cb74-639" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(MultinomialExample)<span class="co"># 产生名为x维度为100*30的矩阵 ,名为y长度为100的数字向量（水平1,2,3组成）训练是内部自动转换</span></span>
<span id="cb74-640"><a href="#cb74-640" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> MultinomialExample<span class="sc">$</span>x</span>
<span id="cb74-641"><a href="#cb74-641" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> MultinomialExample<span class="sc">$</span>y</span>
<span id="cb74-642"><a href="#cb74-642" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-643"><a href="#cb74-643" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.2.2 拟合模型</span></span>
<span id="cb74-644"><a href="#cb74-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-645"><a href="#cb74-645" aria-hidden="true" tabindex="-1"></a>多分类逻辑回归的模型拟和二分类逻辑回归类似，只是这里新增加了一个特殊的参数<span class="in">`type.multinomial`</span>，当<span class="in">`type.multinomial = "grouped"`</span>时，模型拟合时会让每个变量前面的系数全为0或者全不为零，其实就是对于每个类建立逻辑回归时所用到的变量完全相同。</span>
<span id="cb74-646"><a href="#cb74-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-649"><a href="#cb74-649" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-650"><a href="#cb74-650" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"multinomial"</span>, <span class="at">type.multinomial =</span> <span class="st">"grouped"</span>)</span>
<span id="cb74-651"><a href="#cb74-651" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-652"><a href="#cb74-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-653"><a href="#cb74-653" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.2.3 查看拟合效果</span></span>
<span id="cb74-654"><a href="#cb74-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-655"><a href="#cb74-655" aria-hidden="true" tabindex="-1"></a>用<span class="in">`plot`</span>查看模型拟合结果：</span>
<span id="cb74-656"><a href="#cb74-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-659"><a href="#cb74-659" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-660"><a href="#cb74-660" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>, <span class="at">type.coef =</span> <span class="st">"2norm"</span>)</span>
<span id="cb74-661"><a href="#cb74-661" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit, <span class="at">xvar =</span> <span class="st">"lambda"</span>, <span class="at">label =</span> <span class="cn">TRUE</span>, <span class="at">type.coef =</span> <span class="st">"coef"</span>)</span>
<span id="cb74-662"><a href="#cb74-662" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-663"><a href="#cb74-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-664"><a href="#cb74-664" aria-hidden="true" tabindex="-1"></a>这里<span class="in">`xvar`</span>和<span class="in">`label`</span>的使用和之前相同，但是多了一个<span class="in">`type.coef`</span>选项，这个选项仅适用于对多分类逻辑回归以及多响应变量线性回归，若<span class="in">`type.coef = "coef"`</span>会用多张图分别展示每个响应变量的系数，若<span class="in">`type.coef = "2norm"`</span>则会展示系数的L2-范数。 </span>
<span id="cb74-665"><a href="#cb74-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-666"><a href="#cb74-666" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4.2.4 交叉验证和预测</span></span>
<span id="cb74-667"><a href="#cb74-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-668"><a href="#cb74-668" aria-hidden="true" tabindex="-1"></a>我们同样也可以做交叉验证：</span>
<span id="cb74-669"><a href="#cb74-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-672"><a href="#cb74-672" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-673"><a href="#cb74-673" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb74-674"><a href="#cb74-674" aria-hidden="true" tabindex="-1"></a><span class="co"># Windows System</span></span>
<span id="cb74-675"><a href="#cb74-675" aria-hidden="true" tabindex="-1"></a>cl<span class="ot">&lt;-</span><span class="fu">makeCluster</span>(<span class="dv">7</span>)</span>
<span id="cb74-676"><a href="#cb74-676" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cl)</span>
<span id="cb74-677"><a href="#cb74-677" aria-hidden="true" tabindex="-1"></a>cvfit<span class="ot">=</span><span class="fu">cv.glmnet</span>(x, y, <span class="at">family=</span><span class="st">"multinomial"</span>, <span class="at">type.multinomial =</span> <span class="st">"grouped"</span>, <span class="at">parallel =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-678"><a href="#cb74-678" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cl)</span>
<span id="cb74-679"><a href="#cb74-679" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cvfit)</span>
<span id="cb74-680"><a href="#cb74-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-681"><a href="#cb74-681" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-682"><a href="#cb74-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-683"><a href="#cb74-683" aria-hidden="true" tabindex="-1"></a>用拟合的模型来预测： </span>
<span id="cb74-684"><a href="#cb74-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-687"><a href="#cb74-687" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-688"><a href="#cb74-688" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(cvfit, <span class="at">newx =</span> x[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,], <span class="at">s =</span> <span class="st">"lambda.min"</span>, <span class="at">type =</span> <span class="st">"class"</span>)</span>
<span id="cb74-689"><a href="#cb74-689" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-690"><a href="#cb74-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-691"><a href="#cb74-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-692"><a href="#cb74-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-693"><a href="#cb74-693" aria-hidden="true" tabindex="-1"></a><span class="fu">## 5 泊松回归</span></span>
<span id="cb74-694"><a href="#cb74-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-695"><a href="#cb74-695" aria-hidden="true" tabindex="-1"></a>泊松回归经常会用到计数模型中，假定其误差满足泊松分布。</span>
<span id="cb74-696"><a href="#cb74-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-697"><a href="#cb74-697" aria-hidden="true" tabindex="-1"></a>经常用其均值的对数来建模：$\log \mu(x) = \beta_0+\beta' x$.</span>
<span id="cb74-698"><a href="#cb74-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-699"><a href="#cb74-699" aria-hidden="true" tabindex="-1"></a>给定  $<span class="sc">\{</span>x_i,y_i<span class="sc">\}</span>_1^N$下的对数似然为:</span>
<span id="cb74-700"><a href="#cb74-700" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-701"><a href="#cb74-701" aria-hidden="true" tabindex="-1"></a>l(\beta|X, Y) = \sum_{i=1}^N (y_i (\beta_0+\beta' x_i) - e^{\beta_0+\beta^Tx_i}.</span>
<span id="cb74-702"><a href="#cb74-702" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-703"><a href="#cb74-703" aria-hidden="true" tabindex="-1"></a>于是问题变成优化如下带惩罚的对数似然： </span>
<span id="cb74-704"><a href="#cb74-704" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-705"><a href="#cb74-705" aria-hidden="true" tabindex="-1"></a>\min_{\beta_0,\beta} -\frac1N l(\beta|X, Y)  + \lambda \left((1-\alpha) \sum_{i=1}^N \beta_i^2/2) +\alpha \sum_{i=1}^N |\beta_i|\right).</span>
<span id="cb74-706"><a href="#cb74-706" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-707"><a href="#cb74-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-708"><a href="#cb74-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-709"><a href="#cb74-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-710"><a href="#cb74-710" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.1 加载数据集</span></span>
<span id="cb74-711"><a href="#cb74-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-714"><a href="#cb74-714" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-715"><a href="#cb74-715" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(PoissonExample)<span class="co"># 产生名为x维度为500*20的矩阵 ,名为y长度为500的数字向量,全是大于0的数字（泊松函数也是大于0的函数）</span></span>
<span id="cb74-716"><a href="#cb74-716" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> PoissonExample<span class="sc">$</span>x</span>
<span id="cb74-717"><a href="#cb74-717" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> PoissonExample<span class="sc">$</span>y</span>
<span id="cb74-718"><a href="#cb74-718" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-719"><a href="#cb74-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-720"><a href="#cb74-720" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.2 拟合模型</span></span>
<span id="cb74-721"><a href="#cb74-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-722"><a href="#cb74-722" aria-hidden="true" tabindex="-1"></a>采用<span class="in">`glmnet`</span>函数，设置<span class="in">`family = "poisson"`</span>：</span>
<span id="cb74-723"><a href="#cb74-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-726"><a href="#cb74-726" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-727"><a href="#cb74-727" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"poisson"</span>)</span>
<span id="cb74-728"><a href="#cb74-728" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-729"><a href="#cb74-729" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.3 查看拟合效果</span></span>
<span id="cb74-730"><a href="#cb74-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-733"><a href="#cb74-733" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-734"><a href="#cb74-734" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit)</span>
<span id="cb74-735"><a href="#cb74-735" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-736"><a href="#cb74-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-737"><a href="#cb74-737" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5.4 预测</span></span>
<span id="cb74-738"><a href="#cb74-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-739"><a href="#cb74-739" aria-hidden="true" tabindex="-1"></a>用<span class="in">`predict`</span>做预测,在参数选项的设置中，主要是<span class="in">`type`</span>存在一些差异，做出说明如下：</span>
<span id="cb74-740"><a href="#cb74-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-741"><a href="#cb74-741" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“link” 给出线性拟合值</span>
<span id="cb74-742"><a href="#cb74-742" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“response” 给出拟合的均值</span>
<span id="cb74-743"><a href="#cb74-743" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“coefficients” 计算给定<span class="in">`s`</span>下的系数，也可以直接用<span class="in">`coef`</span>函数</span>
<span id="cb74-744"><a href="#cb74-744" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>“nonzero” 返回一个list对象，该list包含每一个<span class="in">`s`</span>对应非零系数的索引</span>
<span id="cb74-745"><a href="#cb74-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-748"><a href="#cb74-748" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-749"><a href="#cb74-749" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fit, <span class="at">s =</span> <span class="dv">1</span>)</span>
<span id="cb74-750"><a href="#cb74-750" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(fit, <span class="at">newx =</span> x[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,], <span class="at">type =</span> <span class="st">"response"</span>, <span class="at">s =</span> <span class="fu">c</span>(<span class="fl">0.1</span>,<span class="dv">1</span>))</span>
<span id="cb74-751"><a href="#cb74-751" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-752"><a href="#cb74-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-753"><a href="#cb74-753" aria-hidden="true" tabindex="-1"></a>我们同样也可以做交叉验证：</span>
<span id="cb74-754"><a href="#cb74-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-757"><a href="#cb74-757" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-758"><a href="#cb74-758" aria-hidden="true" tabindex="-1"></a>cvfit <span class="ot">=</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"poisson"</span>)</span>
<span id="cb74-759"><a href="#cb74-759" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-760"><a href="#cb74-760" aria-hidden="true" tabindex="-1"></a>选项与高斯族几乎相同，除了&nbsp;<span class="in">`type.measure`</span> </span>
<span id="cb74-761"><a href="#cb74-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-762"><a href="#cb74-762" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`cv.glmnet`</span>中<span class="in">`type.measure`</span>的设置：</span>
<span id="cb74-763"><a href="#cb74-763" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>“deviance” 偏差</span>
<span id="cb74-764"><a href="#cb74-764" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>“mse” 均方误差</span>
<span id="cb74-765"><a href="#cb74-765" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>“mae” 平均绝对误差</span>
<span id="cb74-766"><a href="#cb74-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-767"><a href="#cb74-767" aria-hidden="true" tabindex="-1"></a>绘制<span class="in">`cv.glmnet`</span>对象。 </span>
<span id="cb74-768"><a href="#cb74-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-771"><a href="#cb74-771" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-772"><a href="#cb74-772" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cvfit)</span>
<span id="cb74-773"><a href="#cb74-773" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-774"><a href="#cb74-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-775"><a href="#cb74-775" aria-hidden="true" tabindex="-1"></a>提取最优λ对应的模型系数：</span>
<span id="cb74-776"><a href="#cb74-776" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-779"><a href="#cb74-779" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-780"><a href="#cb74-780" aria-hidden="true" tabindex="-1"></a>opt.lam <span class="ot">=</span> <span class="fu">c</span>(cvfit<span class="sc">$</span>lambda.min, cvfit<span class="sc">$</span>lambda<span class="fl">.1</span>se)</span>
<span id="cb74-781"><a href="#cb74-781" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(cvfit, <span class="at">s =</span> opt.lam)</span>
<span id="cb74-782"><a href="#cb74-782" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-783"><a href="#cb74-783" aria-hidden="true" tabindex="-1"></a>可以使用<span class="in">`predict`</span>进行预测，方法类似，在重复 </span>
<span id="cb74-784"><a href="#cb74-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-785"><a href="#cb74-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-786"><a href="#cb74-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-787"><a href="#cb74-787" aria-hidden="true" tabindex="-1"></a><span class="fu">## 6  Cox模型</span></span>
<span id="cb74-788"><a href="#cb74-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-789"><a href="#cb74-789" aria-hidden="true" tabindex="-1"></a>不是很了解。</span>
<span id="cb74-790"><a href="#cb74-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-791"><a href="#cb74-791" aria-hidden="true" tabindex="-1"></a>The Cox proportional hazards model is commonly used for the study of the relationship beteween predictor variables and survival time. In the usual survival analysis framework, we have data of the form $(y_1, x_1, \delta_1), \ldots, (y_n, x_n, \delta_n)$ where $y_i$, the observed time, is a time of failure if $\delta_i$ is 1 or right-censoring if $\delta_i$ is 0. We also let $t_1 &lt; t_2 &lt; \ldots &lt; t_m$ be the increasing list of unique failure times, and $j(i)$ denote the index of the observation failing at time $t_i$.</span>
<span id="cb74-792"><a href="#cb74-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-793"><a href="#cb74-793" aria-hidden="true" tabindex="-1"></a>The Cox model assumes a semi-parametric form for the hazard</span>
<span id="cb74-794"><a href="#cb74-794" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-795"><a href="#cb74-795" aria-hidden="true" tabindex="-1"></a>h_i(t) = h_0(t) e^{x_i^T \beta},</span>
<span id="cb74-796"><a href="#cb74-796" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-797"><a href="#cb74-797" aria-hidden="true" tabindex="-1"></a>where $h_i(t)$ is the hazard for patient $i$ at time $t$, $h_0(t)$ is a shared baseline hazard, and $\beta$ is a fixed, length $p$ vector. In the classic setting $n \geq p$, inference is made via the partial likelihood</span>
<span id="cb74-798"><a href="#cb74-798" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-799"><a href="#cb74-799" aria-hidden="true" tabindex="-1"></a>L(\beta) = \prod_{i=1}^m \frac{e^{x_{j(i)}^T \beta}}{\sum_{j \in R_i} e^{x_j^T \beta}},</span>
<span id="cb74-800"><a href="#cb74-800" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb74-801"><a href="#cb74-801" aria-hidden="true" tabindex="-1"></a>where $R_i$ is the set of indices $j$ with $y_j \geq t_i$ (those at risk at time $t_i$).</span>
<span id="cb74-802"><a href="#cb74-802" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-803"><a href="#cb74-803" aria-hidden="true" tabindex="-1"></a>Note there is no intercept in the Cox mode (its built into the baseline hazard, and like it, would cancel in the partial likelihood.)</span>
<span id="cb74-804"><a href="#cb74-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-805"><a href="#cb74-805" aria-hidden="true" tabindex="-1"></a>We penalize the negative log of the partial likelihood, just like the other models, with an elastic-net penalty.</span>
<span id="cb74-806"><a href="#cb74-806" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-807"><a href="#cb74-807" aria-hidden="true" tabindex="-1"></a><span class="fu">### 6.1 载入数据集</span></span>
<span id="cb74-808"><a href="#cb74-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-809"><a href="#cb74-809" aria-hidden="true" tabindex="-1"></a>同样地，我们加载预先生成好的样本数据和响应变量，但是这里需要注意的是，这里采用了生存分析的分析框架，输入数据略有差别。首先，我们加载数据集：</span>
<span id="cb74-810"><a href="#cb74-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-813"><a href="#cb74-813" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-814"><a href="#cb74-814" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(CoxExample)<span class="co"># 产生名为x的矩阵，其维度为1000*30 ，名为y的矩阵，其维度为1000*2</span></span>
<span id="cb74-815"><a href="#cb74-815" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> CoxExample<span class="sc">$</span>x</span>
<span id="cb74-816"><a href="#cb74-816" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> CoxExample<span class="sc">$</span>y</span>
<span id="cb74-817"><a href="#cb74-817" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,] <span class="co"># status列表示time列对应下的状态，第一列必须是数值型的时间，第二列参数是逻辑向量，0/1表示死亡与否</span></span>
<span id="cb74-818"><a href="#cb74-818" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-819"><a href="#cb74-819" aria-hidden="true" tabindex="-1"></a>可以看到加载的数据还是包含自变量x以及响应变量y两部分：x是n×p维的矩阵；不同的是y，y为$n \times 1$维的矩阵，其中名为<span class="in">`time`</span>的列是观察时间，名为<span class="in">`status`</span>的列为该观察时间下对应的状态，0表示生成，1表示死亡。 </span>
<span id="cb74-820"><a href="#cb74-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-821"><a href="#cb74-821" aria-hidden="true" tabindex="-1"></a><span class="fu">### 6.2 拟合模型</span></span>
<span id="cb74-822"><a href="#cb74-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-823"><a href="#cb74-823" aria-hidden="true" tabindex="-1"></a>同样用<span class="in">`glmnet`</span>建模:</span>
<span id="cb74-824"><a href="#cb74-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-827"><a href="#cb74-827" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-828"><a href="#cb74-828" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"cox"</span>)</span>
<span id="cb74-829"><a href="#cb74-829" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-830"><a href="#cb74-830" aria-hidden="true" tabindex="-1"></a><span class="fu">### 6.3 查看拟合效果</span></span>
<span id="cb74-831"><a href="#cb74-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-834"><a href="#cb74-834" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-835"><a href="#cb74-835" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit)</span>
<span id="cb74-836"><a href="#cb74-836" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-837"><a href="#cb74-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-838"><a href="#cb74-838" aria-hidden="true" tabindex="-1"></a>提取给定  $\lambda$下对应的系数：</span>
<span id="cb74-839"><a href="#cb74-839" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-842"><a href="#cb74-842" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-843"><a href="#cb74-843" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fit, <span class="at">s =</span> <span class="fl">0.05</span>)</span>
<span id="cb74-844"><a href="#cb74-844" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-845"><a href="#cb74-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-846"><a href="#cb74-846" aria-hidden="true" tabindex="-1"></a>由于Cox模型不常用于预测，所以没有给出预测的样例 。如果需要，可以参考帮助文件<span class="in">`help(predict.glmnet)`</span>。 </span>
<span id="cb74-847"><a href="#cb74-847" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-848"><a href="#cb74-848" aria-hidden="true" tabindex="-1"></a><span class="fu">### 6.4 交叉验证</span></span>
<span id="cb74-849"><a href="#cb74-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-850"><a href="#cb74-850" aria-hidden="true" tabindex="-1"></a>用<span class="in">`cv.glmnet`</span>做K折交叉验证时，<span class="in">`type.measure`</span>的选项仅支持“deviance”：</span>
<span id="cb74-851"><a href="#cb74-851" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-854"><a href="#cb74-854" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-855"><a href="#cb74-855" aria-hidden="true" tabindex="-1"></a>cvfit <span class="ot">=</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">family =</span> <span class="st">"cox"</span>)</span>
<span id="cb74-856"><a href="#cb74-856" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-859"><a href="#cb74-859" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-860"><a href="#cb74-860" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cvfit)</span>
<span id="cb74-861"><a href="#cb74-861" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-862"><a href="#cb74-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-863"><a href="#cb74-863" aria-hidden="true" tabindex="-1"></a>提取最优的 $\lambda$ 值</span>
<span id="cb74-866"><a href="#cb74-866" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-867"><a href="#cb74-867" aria-hidden="true" tabindex="-1"></a>cvfit<span class="sc">$</span>lambda.min</span>
<span id="cb74-868"><a href="#cb74-868" aria-hidden="true" tabindex="-1"></a>cvfit<span class="sc">$</span>lambda<span class="fl">.1</span>se</span>
<span id="cb74-869"><a href="#cb74-869" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-870"><a href="#cb74-870" aria-hidden="true" tabindex="-1"></a>提取模型系数： </span>
<span id="cb74-871"><a href="#cb74-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-874"><a href="#cb74-874" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-875"><a href="#cb74-875" aria-hidden="true" tabindex="-1"></a>coef.min <span class="ot">=</span> <span class="fu">coef</span>(cvfit, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb74-876"><a href="#cb74-876" aria-hidden="true" tabindex="-1"></a>active.min <span class="ot">=</span> <span class="fu">which</span>(coef.min <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb74-877"><a href="#cb74-877" aria-hidden="true" tabindex="-1"></a>index.min <span class="ot">=</span> coef.min[active.min]</span>
<span id="cb74-878"><a href="#cb74-878" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-881"><a href="#cb74-881" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-882"><a href="#cb74-882" aria-hidden="true" tabindex="-1"></a>index.min</span>
<span id="cb74-883"><a href="#cb74-883" aria-hidden="true" tabindex="-1"></a>coef.min</span>
<span id="cb74-884"><a href="#cb74-884" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-885"><a href="#cb74-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-886"><a href="#cb74-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-887"><a href="#cb74-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-888"><a href="#cb74-888" aria-hidden="true" tabindex="-1"></a><span class="fu">## 7 稀疏矩阵</span></span>
<span id="cb74-889"><a href="#cb74-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-890"><a href="#cb74-890" aria-hidden="true" tabindex="-1"></a>除了<span class="in">`cox`</span>模型外，<span class="in">`glmnet`</span>均支持稀疏矩阵作为输入，它的用法同常规矩阵的用法相同。</span>
<span id="cb74-891"><a href="#cb74-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-892"><a href="#cb74-892" aria-hidden="true" tabindex="-1"></a>我们加载一个稀疏矩阵示例：</span>
<span id="cb74-893"><a href="#cb74-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-894"><a href="#cb74-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-897"><a href="#cb74-897" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-898"><a href="#cb74-898" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(SparseExample)</span>
<span id="cb74-899"><a href="#cb74-899" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> SparseExample<span class="sc">$</span>x</span>
<span id="cb74-900"><a href="#cb74-900" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> SparseExample<span class="sc">$</span>y</span>
<span id="cb74-901"><a href="#cb74-901" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-902"><a href="#cb74-902" aria-hidden="true" tabindex="-1"></a>加载的数据<span class="in">`x`</span>为100*20的一个稀疏矩阵，<span class="in">`y`</span>为响应变量(长度为100的向量）。</span>
<span id="cb74-905"><a href="#cb74-905" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-906"><a href="#cb74-906" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(x)</span>
<span id="cb74-907"><a href="#cb74-907" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-908"><a href="#cb74-908" aria-hidden="true" tabindex="-1"></a>创建稀疏矩阵有两种方式，一种方式是采用<span class="in">`sparseMatrix`</span>生成；还有一种方式是直接采用<span class="in">`Matrix`</span>来构建。 </span>
<span id="cb74-909"><a href="#cb74-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-910"><a href="#cb74-910" aria-hidden="true" tabindex="-1"></a>当输入是稀疏矩阵时，调用<span class="in">`glmnet`</span>的方式跟普通矩阵没有差别： </span>
<span id="cb74-911"><a href="#cb74-911" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-914"><a href="#cb74-914" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-915"><a href="#cb74-915" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">=</span> <span class="fu">glmnet</span>(x, y)</span>
<span id="cb74-916"><a href="#cb74-916" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-917"><a href="#cb74-917" aria-hidden="true" tabindex="-1"></a>交叉验证也一样： </span>
<span id="cb74-918"><a href="#cb74-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-921"><a href="#cb74-921" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-922"><a href="#cb74-922" aria-hidden="true" tabindex="-1"></a>cvfit <span class="ot">=</span> <span class="fu">cv.glmnet</span>(x, y)</span>
<span id="cb74-923"><a href="#cb74-923" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cvfit)</span>
<span id="cb74-924"><a href="#cb74-924" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-925"><a href="#cb74-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-926"><a href="#cb74-926" aria-hidden="true" tabindex="-1"></a>稀疏矩阵除了可以用作<span class="in">`glmnet`</span>的输入<span class="in">`x`</span>，还可以用作<span class="in">`predict`</span>函数的输入<span class="in">`newx`</span>，我们来看看如下的例子： </span>
<span id="cb74-927"><a href="#cb74-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-930"><a href="#cb74-930" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-931"><a href="#cb74-931" aria-hidden="true" tabindex="-1"></a>i <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="at">size =</span> <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-932"><a href="#cb74-932" aria-hidden="true" tabindex="-1"></a>j <span class="ot">=</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">size =</span> <span class="dv">25</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-933"><a href="#cb74-933" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">25</span>)</span>
<span id="cb74-934"><a href="#cb74-934" aria-hidden="true" tabindex="-1"></a>nx <span class="ot">=</span> <span class="fu">sparseMatrix</span>(<span class="at">i =</span> i, <span class="at">j =</span> j, <span class="at">x =</span> x, <span class="at">dims =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">20</span>))</span>
<span id="cb74-935"><a href="#cb74-935" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(cvfit, <span class="at">newx =</span> nx, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb74-936"><a href="#cb74-936" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-937"><a href="#cb74-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-938"><a href="#cb74-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-939"><a href="#cb74-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-942"><a href="#cb74-942" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb74-943"><a href="#cb74-943" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span>
<span id="cb74-944"><a href="#cb74-944" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb74-945"><a href="#cb74-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-946"><a href="#cb74-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-947"><a href="#cb74-947" aria-hidden="true" tabindex="-1"></a>参考：https://web.stanford.edu/~hastie/glmnet/glmnet_beta.html</span>
<span id="cb74-948"><a href="#cb74-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-949"><a href="#cb74-949" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="复制到剪贴板" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>